# Copyright 2021 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: big-data-passing
  annotations:
    tekton.dev/output_artifacts: '{"gen-params": [{"key": "artifacts/$PIPELINERUN/gen-params/Output.tgz",
      "name": "gen-params-Output", "path": "/tmp/outputs/Output/data"}], "repeat-line":
      [{"key": "artifacts/$PIPELINERUN/repeat-line/output_text.tgz", "name": "repeat-line-output_text",
      "path": "/tmp/outputs/output_text/data"}], "split-text-lines": [{"key": "artifacts/$PIPELINERUN/split-text-lines/even_lines.tgz",
      "name": "split-text-lines-even_lines", "path": "/tmp/outputs/even_lines/data"},
      {"key": "artifacts/$PIPELINERUN/split-text-lines/odd_lines.tgz", "name": "split-text-lines-odd_lines",
      "path": "/tmp/outputs/odd_lines/data"}], "sum-numbers": [{"key": "artifacts/$PIPELINERUN/sum-numbers/Output.tgz",
      "name": "sum-numbers-Output", "path": "/tmp/outputs/Output/data"}], "write-numbers":
      [{"key": "artifacts/$PIPELINERUN/write-numbers/numbers.tgz", "name": "write-numbers-numbers",
      "path": "/tmp/outputs/numbers/data"}]}'
    tekton.dev/input_artifacts: '{"print-params": [{"name": "gen-params-Output", "parent_task":
      "gen-params"}], "print-text": [{"name": "repeat-line-output_text", "parent_task":
      "repeat-line"}], "print-text-2": [{"name": "split-text-lines-odd_lines", "parent_task":
      "split-text-lines"}], "print-text-3": [{"name": "split-text-lines-even_lines",
      "parent_task": "split-text-lines"}], "print-text-4": [{"name": "write-numbers-numbers",
      "parent_task": "write-numbers"}], "print-text-5": [{"name": "sum-numbers-Output",
      "parent_task": "sum-numbers"}], "sum-numbers": [{"name": "write-numbers-numbers",
      "parent_task": "write-numbers"}]}'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"gen-params": [["Output", "$(results.Output.path)"]],
      "print-params": [], "print-text": [], "print-text-2": [], "print-text-3": [],
      "print-text-4": [], "print-text-5": [], "repeat-line": [["output_text", "$(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text"]],
      "split-text-lines": [["even_lines", "$(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines"],
      ["odd_lines", "$(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines"]],
      "sum-numbers": [["Output", "$(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output"]],
      "write-numbers": [["numbers", "$(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers"]]}'
    sidecar.istio.io/inject: "false"
    pipelines.kubeflow.org/big_data_passing_format: $(workspaces.$TASK_NAME.path)/artifacts/$ORIG_PR_NAME/$TASKRUN_NAME/$TASK_PARAM_NAME
    pipelines.kubeflow.org/pipeline_spec: '{"name": "Big data passing"}'
  labels:
    pipelines.kubeflow.org/pipelinename: ''
    pipelines.kubeflow.org/generation: ''
spec:
  pipelineSpec:
    tasks:
    - name: repeat-line
      taskSpec:
        steps:
        - name: main
          args:
          - --line
          - Hello
          - --count
          - '5000'
          - --output-text
          - $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def repeat_line(line, output_text_path, count = 10):
                '''Repeat the line specified number of times'''
                with open(output_text_path, 'w') as writer:
                    for i in range(count):
                        writer.write(line + '\n')

            import argparse
            _parser = argparse.ArgumentParser(prog='Repeat line', description='Repeat the line specified number of times')
            _parser.add_argument("--line", dest="line", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--count", dest="count", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--output-text", dest="output_text_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = repeat_line(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        - image: busybox
          name: output-taskrun-name
          command:
          - sh
          - -ec
          - echo -n "$(context.taskRun.name)" > "$(results.taskrun-name.path)"
        - image: busybox
          name: copy-results-artifacts
          command:
          - sh
          - -ec
          - |
            set -exo pipefail
            TOTAL_SIZE=0
            if [ -d $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text ]; then
              tar -czvf $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text.tar.gz $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text
              SUFFIX=".tar.gz"
            fi
            ARTIFACT_SIZE=`wc -c $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text${SUFFIX} | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.output-text.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              if [ -d $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text ]; then
                tar -tzf $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text.tar.gz > $(results.output-text.path)
              elif ! awk "/[^[:print:]]/{f=1} END{exit !f}" $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text; then
                cp $(workspaces.repeat-line.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/output_text $(results.output-text.path)
              fi
            fi
          onError: continue
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        results:
        - name: output-text
          type: string
          description: /tmp/outputs/output_text/data
        - name: taskrun-name
          type: string
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Repeat line",
              "outputs": [{"name": "output_text", "type": "String"}], "version": "Repeat
              line@sha256=6ba4c40102b73739c02839c46d8897f9b07511608ff42f91916c29fc33ffde37"}'
            tekton.dev/template: ''
        workspaces:
        - name: repeat-line
      timeout: 525600m
      workspaces:
      - name: repeat-line
        workspace: big-data-passing
    - name: split-text-lines
      taskSpec:
        steps:
        - image: busybox
          name: copy-inputs
          command:
          - sh
          - -ec
          - |
            set -exo pipefail
            echo -n "one
            two
            three
            four
            five
            six
            seven
            eight
            nine
            ten" > /tmp/inputs/source/data
        - name: main
          args:
          - --source
          - /tmp/inputs/source/data
          - --odd-lines
          - $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines
          - --even-lines
          - $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def split_text_lines(source_path,
                                 odd_lines_path,
                                 even_lines_path):
                with open(source_path, 'r') as reader:
                    with open(odd_lines_path, 'w') as odd_writer:
                        with open(even_lines_path, 'w') as even_writer:
                            while True:
                                line = reader.readline()
                                if line == "":
                                    break
                                odd_writer.write(line)
                                line = reader.readline()
                                if line == "":
                                    break
                                even_writer.write(line)

            import argparse
            _parser = argparse.ArgumentParser(prog='Split text lines', description='')
            _parser.add_argument("--source", dest="source_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--odd-lines", dest="odd_lines_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--even-lines", dest="even_lines_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = split_text_lines(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        - image: busybox
          name: output-taskrun-name
          command:
          - sh
          - -ec
          - echo -n "$(context.taskRun.name)" > "$(results.taskrun-name.path)"
        - image: busybox
          name: copy-results-artifacts
          command:
          - sh
          - -ec
          - |
            set -exo pipefail
            TOTAL_SIZE=0
            if [ -d $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines ]; then
              tar -czvf $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines.tar.gz $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines
              SUFFIX=".tar.gz"
            fi
            ARTIFACT_SIZE=`wc -c $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines${SUFFIX} | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.odd-lines.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              if [ -d $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines ]; then
                tar -tzf $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines.tar.gz > $(results.odd-lines.path)
              elif ! awk "/[^[:print:]]/{f=1} END{exit !f}" $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines; then
                cp $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/odd_lines $(results.odd-lines.path)
              fi
            fi
            if [ -d $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines ]; then
              tar -czvf $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines.tar.gz $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines
              SUFFIX=".tar.gz"
            fi
            ARTIFACT_SIZE=`wc -c $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines${SUFFIX} | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.even-lines.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              if [ -d $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines ]; then
                tar -tzf $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines.tar.gz > $(results.even-lines.path)
              elif ! awk "/[^[:print:]]/{f=1} END{exit !f}" $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines; then
                cp $(workspaces.split-text-lines.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/even_lines $(results.even-lines.path)
              fi
            fi
          onError: continue
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        results:
        - name: even-lines
          type: string
          description: /tmp/outputs/even_lines/data
        - name: odd-lines
          type: string
          description: /tmp/outputs/odd_lines/data
        - name: taskrun-name
          type: string
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Split text lines",
              "outputs": [{"name": "odd_lines", "type": "String"}, {"name": "even_lines",
              "type": "String"}], "version": "Split text lines@sha256=2922d5cb527a21526cd87d19a93f6d38b9a7607603b85b5b50b700cb013568cb"}'
            tekton.dev/template: ''
        workspaces:
        - name: split-text-lines
        stepTemplate:
          volumeMounts:
          - name: source
            mountPath: /tmp/inputs/source
        volumes:
        - name: source
          emptyDir: {}
      timeout: 525600m
      workspaces:
      - name: split-text-lines
        workspace: big-data-passing
    - name: print-text-2
      params:
      - name: split-text-lines-trname
        value: $(tasks.split-text-lines.results.taskrun-name)
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-2.path)/artifacts/$ORIG_PR_NAME/$(params.split-text-lines-trname)/odd_lines
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        params:
        - name: split-text-lines-trname
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Print text",
              "outputs": [], "version": "Print text@sha256=7840827b663006501280bd895395a3ff9cf8fe2d9b1c9ca8c15f57c17a187318"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-2
      timeout: 525600m
      workspaces:
      - name: print-text-2
        workspace: big-data-passing
      runAfter:
      - split-text-lines
    - name: print-text-3
      params:
      - name: split-text-lines-trname
        value: $(tasks.split-text-lines.results.taskrun-name)
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-3.path)/artifacts/$ORIG_PR_NAME/$(params.split-text-lines-trname)/even_lines
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        params:
        - name: split-text-lines-trname
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Print text",
              "outputs": [], "version": "Print text@sha256=7840827b663006501280bd895395a3ff9cf8fe2d9b1c9ca8c15f57c17a187318"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-3
      timeout: 525600m
      workspaces:
      - name: print-text-3
        workspace: big-data-passing
      runAfter:
      - split-text-lines
    - name: write-numbers
      taskSpec:
        steps:
        - name: main
          args:
          - --start
          - '0'
          - --count
          - '100000'
          - --numbers
          - $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def write_numbers(
                    numbers_path, start = 0, count = 10):
                with open(numbers_path, 'w') as writer:
                    for i in range(start, count):
                        writer.write(str(i) + '\n')

            import argparse
            _parser = argparse.ArgumentParser(prog='Write numbers', description='')
            _parser.add_argument("--start", dest="start", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--count", dest="count", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--numbers", dest="numbers_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = write_numbers(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        - image: busybox
          name: output-taskrun-name
          command:
          - sh
          - -ec
          - echo -n "$(context.taskRun.name)" > "$(results.taskrun-name.path)"
        - image: busybox
          name: copy-results-artifacts
          command:
          - sh
          - -ec
          - |
            set -exo pipefail
            TOTAL_SIZE=0
            if [ -d $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers ]; then
              tar -czvf $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers.tar.gz $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers
              SUFFIX=".tar.gz"
            fi
            ARTIFACT_SIZE=`wc -c $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers${SUFFIX} | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.numbers.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              if [ -d $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers ]; then
                tar -tzf $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers.tar.gz > $(results.numbers.path)
              elif ! awk "/[^[:print:]]/{f=1} END{exit !f}" $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers; then
                cp $(workspaces.write-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/numbers $(results.numbers.path)
              fi
            fi
          onError: continue
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        results:
        - name: numbers
          type: string
          description: /tmp/outputs/numbers/data
        - name: taskrun-name
          type: string
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Write numbers",
              "outputs": [{"name": "numbers", "type": "String"}], "version": "Write
              numbers@sha256=6a144669e9261686cc1f2365c56bc2ff9a575dd7d02049ea5580b1d40d2a2808"}'
            tekton.dev/template: ''
        workspaces:
        - name: write-numbers
      timeout: 525600m
      workspaces:
      - name: write-numbers
        workspace: big-data-passing
    - name: print-text-4
      params:
      - name: write-numbers-trname
        value: $(tasks.write-numbers.results.taskrun-name)
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-4.path)/artifacts/$ORIG_PR_NAME/$(params.write-numbers-trname)/numbers
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        params:
        - name: write-numbers-trname
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Print text",
              "outputs": [], "version": "Print text@sha256=7840827b663006501280bd895395a3ff9cf8fe2d9b1c9ca8c15f57c17a187318"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-4
      timeout: 525600m
      workspaces:
      - name: print-text-4
        workspace: big-data-passing
      runAfter:
      - write-numbers
    - name: sum-numbers
      params:
      - name: write-numbers-trname
        value: $(tasks.write-numbers.results.taskrun-name)
      taskSpec:
        steps:
        - name: main
          args:
          - --numbers
          - $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(params.write-numbers-trname)/numbers
          - '----output-paths'
          - $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def sum_numbers(numbers_path):
                sum = 0
                with open(numbers_path, 'r') as reader:
                    for line in reader:
                        sum = sum + int(line)
                return sum

            def _serialize_int(int_value: int) -> str:
                if isinstance(int_value, str):
                    return int_value
                if not isinstance(int_value, int):
                    raise TypeError('Value "{}" has type "{}" instead of int.'.format(
                        str(int_value), str(type(int_value))))
                return str(int_value)

            import argparse
            _parser = argparse.ArgumentParser(prog='Sum numbers', description='')
            _parser.add_argument("--numbers", dest="numbers_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = sum_numbers(**_parsed_args)

            _outputs = [_outputs]

            _output_serializers = [
                _serialize_int,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        - image: busybox
          name: output-taskrun-name
          command:
          - sh
          - -ec
          - echo -n "$(context.taskRun.name)" > "$(results.taskrun-name.path)"
        - image: busybox
          name: copy-results-artifacts
          command:
          - sh
          - -ec
          - |
            set -exo pipefail
            TOTAL_SIZE=0
            if [ -d $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output ]; then
              tar -czvf $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output.tar.gz $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output
              SUFFIX=".tar.gz"
            fi
            ARTIFACT_SIZE=`wc -c $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output${SUFFIX} | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.Output.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              if [ -d $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output ]; then
                tar -tzf $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output.tar.gz > $(results.Output.path)
              elif ! awk "/[^[:print:]]/{f=1} END{exit !f}" $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output; then
                cp $(workspaces.sum-numbers.path)/artifacts/$ORIG_PR_NAME/$(context.taskRun.name)/Output $(results.Output.path)
              fi
            fi
          onError: continue
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        params:
        - name: write-numbers-trname
        results:
        - name: Output
          type: string
          description: /tmp/outputs/Output/data
        - name: taskrun-name
          type: string
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Sum numbers",
              "outputs": [{"name": "Output", "type": "Integer"}], "version": "Sum
              numbers@sha256=c3f155c05c526db1acfedc8894328f5abb2c00f9378e1c5f89d035682aa2e9d7"}'
            tekton.dev/template: ''
        workspaces:
        - name: sum-numbers
      timeout: 525600m
      workspaces:
      - name: sum-numbers
        workspace: big-data-passing
      runAfter:
      - write-numbers
    - name: print-text-5
      params:
      - name: sum-numbers-trname
        value: $(tasks.sum-numbers.results.taskrun-name)
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-5.path)/artifacts/$ORIG_PR_NAME/$(params.sum-numbers-trname)/Output
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
          env:
          - name: ORIG_PR_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
        params:
        - name: sum-numbers-trname
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Print text",
              "outputs": [], "version": "Print text@sha256=7840827b663006501280bd895395a3ff9cf8fe2d9b1c9ca8c15f57c17a187318"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-5
      timeout: 525600m
      workspaces:
      - name: print-text-5
        workspace: big-data-passing
      runAfter:
      - sum-numbers
    - name: gen-params
      taskSpec:
        steps:
        - name: main
          args:
          - '----output-paths'
          - $(results.Output.path)
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def gen_params():
                import random
                num = random.randint(0, 9)
                return num

            def _serialize_int(int_value: int) -> str:
                if isinstance(int_value, str):
                    return int_value
                if not isinstance(int_value, int):
                    raise TypeError('Value "{}" has type "{}" instead of int.'.format(
                        str(int_value), str(type(int_value))))
                return str(int_value)

            import argparse
            _parser = argparse.ArgumentParser(prog='Gen params', description='')
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = gen_params(**_parsed_args)

            _outputs = [_outputs]

            _output_serializers = [
                _serialize_int,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
          image: python:3.7
        results:
        - name: Output
          type: string
          description: /tmp/outputs/Output/data
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Gen params",
              "outputs": [{"name": "Output", "type": "Integer"}], "version": "Gen
              params@sha256=3453ee878d06fc3c3d7987bab4a5a1633c65c6b860fc9b41e745d8400a483a26"}'
            tekton.dev/template: ''
      timeout: 525600m
    - name: print-params
      params:
      - name: gen-params-Output
        value: $(tasks.gen-params.results.Output)
      taskSpec:
        steps:
        - name: main
          args:
          - --numbers-parm
          - $(inputs.params.gen-params-Output)
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_params(numbers_parm):
                print("The result number is: %d" % numbers_parm)

            import argparse
            _parser = argparse.ArgumentParser(prog='Print params', description='')
            _parser.add_argument("--numbers-parm", dest="numbers_parm", type=int, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_params(**_parsed_args)
          image: python:3.7
        params:
        - name: gen-params-Output
        metadata:
          labels:
            pipelines.kubeflow.org/cache_enabled: "true"
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
          annotations:
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Print params",
              "outputs": [], "version": "Print params@sha256=3fb942e817debe20ad7b6a10ff15f184d01b788e9908d665b20ecc89e7bb48da"}'
            tekton.dev/template: ''
      timeout: 525600m
    - runAfter:
      - repeat-line
      name: big-data-passing-for-loop-2
      params:
      - name: loop-item-param-1
        value: '[1, 2]'
      - name: repeat-line-output_text
        value: $(tasks.repeat-line.results.output-text)
      - name: repeat-line-taskrun-name
        value: $(tasks.repeat-line.results.taskrun-name)
      taskSpec:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        spec:
          pipelineSpec:
            params:
            - name: loop-item-param-1
              type: string
            - name: repeat-line-output_text
              type: string
            - name: repeat-line-taskrun-name
              type: string
            tasks:
            - name: big-data-passing-for-loop-4
              params:
              - name: loop-item-param-3
                value: '[1, 2]'
              - name: repeat-line-output_text
                value: $(params.repeat-line-output_text)
              - name: repeat-line-taskrun-name
                value: $(params.repeat-line-taskrun-name)
              taskSpec:
                apiVersion: custom.tekton.dev/v1alpha1
                kind: PipelineLoop
                spec:
                  pipelineSpec:
                    params:
                    - name: loop-item-param-3
                      type: string
                    - name: repeat-line-output_text
                      type: string
                    - name: repeat-line-taskrun-name
                      type: string
                    tasks:
                    - name: print-text
                      params:
                      - name: repeat-line-trname
                        value: $(params.repeat-line-taskrun-name)
                      taskSpec:
                        steps:
                        - name: main
                          args:
                          - --text
                          - $(workspaces.print-text.path)/artifacts/$ORIG_PR_NAME/$(params.repeat-line-trname)/output_text
                          command:
                          - sh
                          - -ec
                          - |
                            program_path=$(mktemp)
                            printf "%s" "$0" > "$program_path"
                            python3 -u "$program_path" "$@"
                          - |
                            def print_text(
                                    text_path
                            ):  # The "text" input is untyped so that any data can be printed
                                '''Print text'''
                                with open(text_path, 'r') as reader:
                                    for line in reader:
                                        print(line, end='')

                            import argparse
                            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
                            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
                            _parsed_args = vars(_parser.parse_args())

                            _outputs = print_text(**_parsed_args)
                          image: python:3.7
                          env:
                          - name: ORIG_PR_NAME
                            valueFrom:
                              fieldRef:
                                fieldPath: metadata.labels['custom.tekton.dev/originalPipelineRun']
                        params:
                        - name: repeat-line-trname
                          type: string
                        metadata:
                          labels:
                            pipelines.kubeflow.org/cache_enabled: "true"
                            pipelines.kubeflow.org/pipelinename: ''
                            pipelines.kubeflow.org/generation: ''
                          annotations:
                            pipelines.kubeflow.org/component_spec_digest: '{"name":
                              "Print text", "outputs": [], "version": "Print text@sha256=7840827b663006501280bd895395a3ff9cf8fe2d9b1c9ca8c15f57c17a187318"}'
                            tekton.dev/template: ''
                        workspaces:
                        - name: print-text
                      timeout: 525600m
                      workspaces:
                      - name: print-text
                        workspace: big-data-passing
                      runAfter: []
                    workspaces:
                    - name: big-data-passing
                  iterateParam: loop-item-param-3
                  workspaces:
                  - name: big-data-passing
                    volumeClaimTemplate:
                      spec:
                        storageClassName: kfp-csi-s3
                        accessModes:
                        - ReadWriteMany
                        resources:
                          requests:
                            storage: 2Gi
                metadata:
                  labels:
                    pipelines.kubeflow.org/pipelinename: ''
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/cache_enabled: "true"
            workspaces:
            - name: big-data-passing
          iterateParam: loop-item-param-1
          workspaces:
          - name: big-data-passing
            volumeClaimTemplate:
              spec:
                storageClassName: kfp-csi-s3
                accessModes:
                - ReadWriteMany
                resources:
                  requests:
                    storage: 2Gi
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
    workspaces:
    - name: big-data-passing
  timeout: 525600m
  workspaces:
  - name: big-data-passing
    volumeClaimTemplate:
      spec:
        storageClassName: kfp-csi-s3
        accessModes:
        - ReadWriteMany
        resources:
          requests:
            storage: 2Gi
