# Copyright 2020 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"name": "File passing pipelines"}'
    sidecar.istio.io/inject: 'false'
    tekton.dev/input_artifacts: '{}'
    tekton.dev/output_artifacts: '{}'
  labels:
    pipelines.kubeflow.org/pipeline-sdk-type: kfp
  name: file-passing-pipelines
spec:
  pipelineSpec:
    tasks:
    - name: repeat-line
      taskSpec:
        results:
        - description: /tmp/outputs/output_text/data
          name: output_text
        steps:
        - args:
          - --line
          - Hello
          - --count
          - '5000'
          - --output-text
          - $(results.output-text.path)
          command:
          - python3
          - -u
          - -c
          - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n\
            \    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return\
            \ file_path\n\ndef repeat_line(line , output_text_path , count  = 10):\n\
            \    '''Repeat the line specified number of times'''\n    with open(output_text_path,\
            \ 'w') as writer:\n        for i in range(count):\n            writer.write(line\
            \ + '\\n')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Repeat\
            \ line', description='Repeat the line specified number of times')\n_parser.add_argument(\"\
            --line\", dest=\"line\", type=str, required=True, default=argparse.SUPPRESS)\n\
            _parser.add_argument(\"--count\", dest=\"count\", type=int, required=False,\
            \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-text\",\
            \ dest=\"output_text_path\", type=_make_parent_dirs_and_return_path, required=True,\
            \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
            _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs =\
            \ repeat_line(**_parsed_args)\n\n_output_serializers = [\n\n]\n\nimport\
            \ os\nfor idx, output_file in enumerate(_output_files):\n    try:\n  \
            \      os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
            \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: print-text
      params:
      - name: repeat-line-output_text
        value: $(tasks.repeat-line.results.output_text)
      taskSpec:
        artifacts:
        - name: text
          path: /tmp/inputs/text/data
          raw:
            data: $(inputs.params.repeat-line-output_text)
        params:
        - name: repeat-line-output_text
        steps:
        - args:
          - --text
          - /tmp/inputs/text/data
          command:
          - python3
          - -u
          - -c
          - "def print_text(\n        text_path \n):  # The \"text\" input is untyped\
            \ so that any data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end='')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: split-text-lines
      taskSpec:
        artifacts:
        - name: source
          path: /tmp/inputs/source/data
          raw:
            data: 'one

              two

              three

              four

              five

              six

              seven

              eight

              nine

              ten'
        results:
        - description: /tmp/outputs/odd_lines/data
          name: odd_lines
        - description: /tmp/outputs/even_lines/data
          name: even_lines
        steps:
        - args:
          - --source
          - /tmp/inputs/source/data
          - --odd-lines
          - $(results.odd-lines.path)
          - --even-lines
          - $(results.even-lines.path)
          command:
          - python3
          - -u
          - -c
          - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n\
            \    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return\
            \ file_path\n\ndef split_text_lines(source_path ,\n                  \
            \   odd_lines_path ,\n                     even_lines_path ):\n    with\
            \ open(source_path, 'r') as reader:\n        with open(odd_lines_path,\
            \ 'w') as odd_writer:\n            with open(even_lines_path, 'w') as\
            \ even_writer:\n                while True:\n                    line\
            \ = reader.readline()\n                    if line == \"\":\n        \
            \                break\n                    odd_writer.write(line)\n \
            \                   line = reader.readline()\n                    if line\
            \ == \"\":\n                        break\n                    even_writer.write(line)\n\
            \nimport argparse\n_parser = argparse.ArgumentParser(prog='Split text\
            \ lines', description='')\n_parser.add_argument(\"--source\", dest=\"\
            source_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
            --odd-lines\", dest=\"odd_lines_path\", type=_make_parent_dirs_and_return_path,\
            \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--even-lines\"\
            , dest=\"even_lines_path\", type=_make_parent_dirs_and_return_path, required=True,\
            \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
            _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs =\
            \ split_text_lines(**_parsed_args)\n\n_output_serializers = [\n\n]\n\n\
            import os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
            \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
            \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: print-text-2
      params:
      - name: split-text-lines-odd_lines
        value: $(tasks.split-text-lines.results.odd_lines)
      taskSpec:
        artifacts:
        - name: text
          path: /tmp/inputs/text/data
          raw:
            data: $(inputs.params.split-text-lines-odd_lines)
        params:
        - name: split-text-lines-odd_lines
        steps:
        - args:
          - --text
          - /tmp/inputs/text/data
          command:
          - python3
          - -u
          - -c
          - "def print_text(\n        text_path \n):  # The \"text\" input is untyped\
            \ so that any data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end='')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: print-text-3
      params:
      - name: split-text-lines-even_lines
        value: $(tasks.split-text-lines.results.even_lines)
      taskSpec:
        artifacts:
        - name: text
          path: /tmp/inputs/text/data
          raw:
            data: $(inputs.params.split-text-lines-even_lines)
        params:
        - name: split-text-lines-even_lines
        steps:
        - args:
          - --text
          - /tmp/inputs/text/data
          command:
          - python3
          - -u
          - -c
          - "def print_text(\n        text_path \n):  # The \"text\" input is untyped\
            \ so that any data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end='')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: write-numbers
      taskSpec:
        results:
        - description: /tmp/outputs/numbers/data
          name: numbers
        steps:
        - args:
          - --count
          - '100000'
          - --numbers
          - $(results.numbers.path)
          command:
          - python3
          - -u
          - -c
          - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n\
            \    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return\
            \ file_path\n\ndef write_numbers(\n        numbers_path , start  = 0,\
            \ count  = 10):\n    with open(numbers_path, 'w') as writer:\n       \
            \ for i in range(start, count):\n            writer.write(str(i) + '\\\
            n')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Write\
            \ numbers', description='')\n_parser.add_argument(\"--start\", dest=\"\
            start\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
            --count\", dest=\"count\", type=int, required=False, default=argparse.SUPPRESS)\n\
            _parser.add_argument(\"--numbers\", dest=\"numbers_path\", type=_make_parent_dirs_and_return_path,\
            \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
            _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs =\
            \ write_numbers(**_parsed_args)\n\n_output_serializers = [\n\n]\n\nimport\
            \ os\nfor idx, output_file in enumerate(_output_files):\n    try:\n  \
            \      os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
            \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: print-text-4
      params:
      - name: write-numbers-numbers
        value: $(tasks.write-numbers.results.numbers)
      taskSpec:
        artifacts:
        - name: text
          path: /tmp/inputs/text/data
          raw:
            data: $(inputs.params.write-numbers-numbers)
        params:
        - name: write-numbers-numbers
        steps:
        - args:
          - --text
          - /tmp/inputs/text/data
          command:
          - python3
          - -u
          - -c
          - "def print_text(\n        text_path \n):  # The \"text\" input is untyped\
            \ so that any data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end='')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: sum-numbers
      params:
      - name: write-numbers-numbers
        value: $(tasks.write-numbers.results.numbers)
      taskSpec:
        artifacts:
        - name: numbers
          path: /tmp/inputs/numbers/data
          raw:
            data: $(inputs.params.write-numbers-numbers)
        params:
        - name: write-numbers-numbers
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - --numbers
          - /tmp/inputs/numbers/data
          - '----output-paths'
          - $(results.output.path)
          command:
          - python3
          - -u
          - -c
          - "def sum_numbers(numbers_path )  :\n    sum = 0\n    with open(numbers_path,\
            \ 'r') as reader:\n        for line in reader:\n            sum = sum\
            \ + int(line)\n    return sum\n\ndef _serialize_int(int_value: int) ->\
            \ str:\n    if isinstance(int_value, str):\n        return int_value\n\
            \    if not isinstance(int_value, int):\n        raise TypeError('Value\
            \ \"{}\" has type \"{}\" instead of int.'.format(str(int_value), str(type(int_value))))\n\
            \    return str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Sum\
            \ numbers', description='')\n_parser.add_argument(\"--numbers\", dest=\"\
            numbers_path\", type=str, required=True, default=argparse.SUPPRESS)\n\
            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
            \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files =\
            \ _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = sum_numbers(**_parsed_args)\n\
            \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\
            \n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: print-text-5
      params:
      - name: sum-numbers-output
        value: $(tasks.sum-numbers.results.output)
      taskSpec:
        artifacts:
        - name: text
          path: /tmp/inputs/text/data
          raw:
            data: $(inputs.params.sum-numbers-output)
        params:
        - name: sum-numbers-output
        steps:
        - args:
          - --text
          - /tmp/inputs/text/data
          command:
          - python3
          - -u
          - -c
          - "def print_text(\n        text_path \n):  # The \"text\" input is untyped\
            \ so that any data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end='')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: gen-params
      taskSpec:
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - '----output-paths'
          - $(results.output.path)
          command:
          - python3
          - -u
          - -c
          - "def gen_params()  :\n    import random\n    num = random.randint(0, 9)\n\
            \    return num\n\ndef _serialize_int(int_value: int) -> str:\n    if\
            \ isinstance(int_value, str):\n        return int_value\n    if not isinstance(int_value,\
            \ int):\n        raise TypeError('Value \"{}\" has type \"{}\" instead\
            \ of int.'.format(str(int_value), str(type(int_value))))\n    return str(int_value)\n\
            \nimport argparse\n_parser = argparse.ArgumentParser(prog='Gen params',\
            \ description='')\n_parser.add_argument(\"----output-paths\", dest=\"\
            _output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
            _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs =\
            \ gen_params(**_parsed_args)\n\n_outputs = [_outputs]\n\n_output_serializers\
            \ = [\n    _serialize_int,\n\n]\n\nimport os\nfor idx, output_file in\
            \ enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
            \    except OSError:\n        pass\n    with open(output_file, 'w') as\
            \ f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
    - name: print-params
      params:
      - name: gen-params-output
        value: $(tasks.gen-params.results.output)
      taskSpec:
        params:
        - name: gen-params-output
        steps:
        - args:
          - --numbers-parm
          - $(inputs.params.gen-params-output)
          command:
          - python3
          - -u
          - -c
          - "def print_params(numbers_parm ):\n    print(\"The result number is: %d\"\
            \ % numbers_parm)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ params', description='')\n_parser.add_argument(\"--numbers-parm\", dest=\"\
            numbers_parm\", type=int, required=True, default=argparse.SUPPRESS)\n\
            _parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
            _output_paths\", [])\n\n_outputs = print_params(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
