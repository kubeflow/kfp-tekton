# Copyright 2021 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: big-data-passing
  annotations:
    tekton.dev/output_artifacts: '{"gen-params": [{"key": "artifacts/$PIPELINERUN/gen-params/Output.tgz",
      "name": "gen-params-Output", "path": "/tmp/outputs/Output/data"}], "repeat-line":
      [{"key": "artifacts/$PIPELINERUN/repeat-line/output_text.tgz", "name": "repeat-line-output_text",
      "path": "/tmp/outputs/output_text/data"}], "split-text-lines": [{"key": "artifacts/$PIPELINERUN/split-text-lines/even_lines.tgz",
      "name": "split-text-lines-even_lines", "path": "/tmp/outputs/even_lines/data"},
      {"key": "artifacts/$PIPELINERUN/split-text-lines/odd_lines.tgz", "name": "split-text-lines-odd_lines",
      "path": "/tmp/outputs/odd_lines/data"}], "sum-numbers": [{"key": "artifacts/$PIPELINERUN/sum-numbers/Output.tgz",
      "name": "sum-numbers-Output", "path": "/tmp/outputs/Output/data"}], "write-numbers":
      [{"key": "artifacts/$PIPELINERUN/write-numbers/numbers.tgz", "name": "write-numbers-numbers",
      "path": "/tmp/outputs/numbers/data"}]}'
    tekton.dev/input_artifacts: '{"print-params": [{"name": "gen-params-Output", "parent_task":
      "gen-params"}], "print-text": [{"name": "repeat-line-output_text", "parent_task":
      "repeat-line"}], "print-text-2": [{"name": "split-text-lines-odd_lines", "parent_task":
      "split-text-lines"}], "print-text-3": [{"name": "split-text-lines-even_lines",
      "parent_task": "split-text-lines"}], "print-text-4": [{"name": "write-numbers-numbers",
      "parent_task": "write-numbers"}], "print-text-5": [{"name": "sum-numbers-Output",
      "parent_task": "sum-numbers"}], "sum-numbers": [{"name": "write-numbers-numbers",
      "parent_task": "write-numbers"}]}'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"gen-params": [["Output", "$(results.output.path)"]],
      "print-params": [], "print-text": [], "print-text-2": [], "print-text-3": [],
      "print-text-4": [], "print-text-5": [], "repeat-line": [["output_text", "$(workspaces.repeat-line.path)/artifacts/$(context.pipelineRun.name)/repeat-line/output_text"]],
      "split-text-lines": [["even_lines", "$(workspaces.split-text-lines.path)/artifacts/$(context.pipelineRun.name)/split-text-lines/even_lines"],
      ["odd_lines", "$(workspaces.split-text-lines.path)/artifacts/$(context.pipelineRun.name)/split-text-lines/odd_lines"]],
      "sum-numbers": [["Output", "$(workspaces.sum-numbers.path)/artifacts/$(context.pipelineRun.name)/sum-numbers/Output"]],
      "write-numbers": [["numbers", "$(workspaces.write-numbers.path)/artifacts/$(context.pipelineRun.name)/write-numbers/numbers"]]}'
    sidecar.istio.io/inject: "false"
    pipelines.kubeflow.org/pipeline_spec: '{"name": "Big data passing"}'
spec:
  pipelineSpec:
    tasks:
    - name: repeat-line
      taskSpec:
        steps:
        - name: main
          args:
          - --line
          - Hello
          - --count
          - '5000'
          - --output-text
          - $(workspaces.repeat-line.path)/artifacts/$(params.pipelineRun-name)/repeat-line/output_text
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def repeat_line(line, output_text_path, count = 10):
                '''Repeat the line specified number of times'''
                with open(output_text_path, 'w') as writer:
                    for i in range(count):
                        writer.write(line + '\n')

            import argparse
            _parser = argparse.ArgumentParser(prog='Repeat line', description='Repeat the line specified number of times')
            _parser.add_argument("--line", dest="line", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--count", dest="count", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--output-text", dest="output_text_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = repeat_line(**_parsed_args)
          image: python:3.7
        - image: busybox
          name: copy-results-artifacts
          script: |
            #!/bin/sh
            set -exo pipefail
            TOTAL_SIZE=0
            ARTIFACT_SIZE=`wc -c $(workspaces.repeat-line.path)/artifacts/$(params.pipelineRun-name)/repeat-line/output_text | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.output-text.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              cp $(workspaces.repeat-line.path)/artifacts/$(params.pipelineRun-name)/repeat-line/output_text $(results.output-text.path)
            fi
          onError: continue
        results:
        - name: output-text
          description: /tmp/outputs/output_text/data
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"description": "Repeat the line
              specified number of times", "implementation": {"container": {"args":
              ["--line", {"inputValue": "line"}, {"if": {"cond": {"isPresent": "count"},
              "then": ["--count", {"inputValue": "count"}]}}, "--output-text", {"outputPath":
              "output_text"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
              \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import
              os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
              file_path\n\ndef repeat_line(line, output_text_path, count = 10):\n    ''''''Repeat
              the line specified number of times''''''\n    with open(output_text_path,
              ''w'') as writer:\n        for i in range(count):\n            writer.write(line
              + ''\\n'')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Repeat
              line'', description=''Repeat the line specified number of times'')\n_parser.add_argument(\"--line\",
              dest=\"line\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--count\",
              dest=\"count\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-text\",
              dest=\"output_text_path\", type=_make_parent_dirs_and_return_path, required=True,
              default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
              = repeat_line(**_parsed_args)\n"], "image": "python:3.7"}}, "inputs":
              [{"name": "line", "type": "String"}, {"default": "10", "name": "count",
              "optional": true, "type": "Integer"}], "name": "Repeat line", "outputs":
              [{"name": "output_text", "type": "String"}]}'
            tekton.dev/template: ''
        workspaces:
        - name: repeat-line
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: repeat-line
        workspace: big-data-passing
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: print-text
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text.path)/artifacts/$(params.pipelineRun-name)/repeat-line/output_text
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"description": "Print text",
              "implementation": {"container": {"args": ["--text", {"inputPath": "text"}],
              "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
              > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def print_text(\n        text_path\n):  #
              The \"text\" input is untyped so that any data can be printed\n    ''''''Print
              text''''''\n    with open(text_path, ''r'') as reader:\n        for
              line in reader:\n            print(line, end='''')\n\nimport argparse\n_parser
              = argparse.ArgumentParser(prog=''Print text'', description=''Print text'')\n_parser.add_argument(\"--text\",
              dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = print_text(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "text"}], "name": "Print
              text"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: print-text
        workspace: big-data-passing
      runAfter:
      - repeat-line
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: split-text-lines
      taskSpec:
        steps:
        - image: busybox
          name: copy-inputs
          script: |
            #!/bin/sh
            set -exo pipefail
            echo -n "one
            two
            three
            four
            five
            six
            seven
            eight
            nine
            ten" > /tmp/inputs/source/data
        - name: main
          args:
          - --source
          - /tmp/inputs/source/data
          - --odd-lines
          - $(workspaces.split-text-lines.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/odd_lines
          - --even-lines
          - $(workspaces.split-text-lines.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/even_lines
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def split_text_lines(source_path,
                                 odd_lines_path,
                                 even_lines_path):
                with open(source_path, 'r') as reader:
                    with open(odd_lines_path, 'w') as odd_writer:
                        with open(even_lines_path, 'w') as even_writer:
                            while True:
                                line = reader.readline()
                                if line == "":
                                    break
                                odd_writer.write(line)
                                line = reader.readline()
                                if line == "":
                                    break
                                even_writer.write(line)

            import argparse
            _parser = argparse.ArgumentParser(prog='Split text lines', description='')
            _parser.add_argument("--source", dest="source_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--odd-lines", dest="odd_lines_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--even-lines", dest="even_lines_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = split_text_lines(**_parsed_args)
          image: python:3.7
        - image: busybox
          name: copy-results-artifacts
          script: |
            #!/bin/sh
            set -exo pipefail
            TOTAL_SIZE=0
            ARTIFACT_SIZE=`wc -c $(workspaces.split-text-lines.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/odd_lines | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.odd-lines.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              cp $(workspaces.split-text-lines.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/odd_lines $(results.odd-lines.path)
            fi
            ARTIFACT_SIZE=`wc -c $(workspaces.split-text-lines.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/even_lines | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.even-lines.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              cp $(workspaces.split-text-lines.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/even_lines $(results.even-lines.path)
            fi
          onError: continue
        results:
        - name: odd-lines
          description: /tmp/outputs/odd_lines/data
        - name: even-lines
          description: /tmp/outputs/even_lines/data
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["--source", {"inputPath": "source"}, "--odd-lines", {"outputPath":
              "odd_lines"}, "--even-lines", {"outputPath": "even_lines"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
              str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
              file_path\n\ndef split_text_lines(source_path,\n                     odd_lines_path,\n                     even_lines_path):\n    with
              open(source_path, ''r'') as reader:\n        with open(odd_lines_path,
              ''w'') as odd_writer:\n            with open(even_lines_path, ''w'')
              as even_writer:\n                while True:\n                    line
              = reader.readline()\n                    if line == \"\":\n                        break\n                    odd_writer.write(line)\n                    line
              = reader.readline()\n                    if line == \"\":\n                        break\n                    even_writer.write(line)\n\nimport
              argparse\n_parser = argparse.ArgumentParser(prog=''Split text lines'',
              description='''')\n_parser.add_argument(\"--source\", dest=\"source_path\",
              type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--odd-lines\",
              dest=\"odd_lines_path\", type=_make_parent_dirs_and_return_path, required=True,
              default=argparse.SUPPRESS)\n_parser.add_argument(\"--even-lines\", dest=\"even_lines_path\",
              type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = split_text_lines(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "source", "type": "String"}],
              "name": "Split text lines", "outputs": [{"name": "odd_lines", "type":
              "String"}, {"name": "even_lines", "type": "String"}]}'
            tekton.dev/template: ''
        workspaces:
        - name: split-text-lines
        stepTemplate:
          volumeMounts:
          - name: source
            mountPath: /tmp/inputs/source
        volumes:
        - name: source
          emptyDir: {}
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: split-text-lines
        workspace: big-data-passing
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: print-text-2
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-2.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/odd_lines
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"description": "Print text",
              "implementation": {"container": {"args": ["--text", {"inputPath": "text"}],
              "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
              > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def print_text(\n        text_path\n):  #
              The \"text\" input is untyped so that any data can be printed\n    ''''''Print
              text''''''\n    with open(text_path, ''r'') as reader:\n        for
              line in reader:\n            print(line, end='''')\n\nimport argparse\n_parser
              = argparse.ArgumentParser(prog=''Print text'', description=''Print text'')\n_parser.add_argument(\"--text\",
              dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = print_text(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "text"}], "name": "Print
              text"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-2
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: print-text-2
        workspace: big-data-passing
      runAfter:
      - split-text-lines
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: print-text-3
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-3.path)/artifacts/$(params.pipelineRun-name)/split-text-lines/even_lines
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"description": "Print text",
              "implementation": {"container": {"args": ["--text", {"inputPath": "text"}],
              "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
              > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def print_text(\n        text_path\n):  #
              The \"text\" input is untyped so that any data can be printed\n    ''''''Print
              text''''''\n    with open(text_path, ''r'') as reader:\n        for
              line in reader:\n            print(line, end='''')\n\nimport argparse\n_parser
              = argparse.ArgumentParser(prog=''Print text'', description=''Print text'')\n_parser.add_argument(\"--text\",
              dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = print_text(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "text"}], "name": "Print
              text"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-3
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: print-text-3
        workspace: big-data-passing
      runAfter:
      - split-text-lines
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: write-numbers
      taskSpec:
        steps:
        - name: main
          args:
          - --start
          - '0'
          - --count
          - '100000'
          - --numbers
          - $(workspaces.write-numbers.path)/artifacts/$(params.pipelineRun-name)/write-numbers/numbers
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def write_numbers(
                    numbers_path, start = 0, count = 10):
                with open(numbers_path, 'w') as writer:
                    for i in range(start, count):
                        writer.write(str(i) + '\n')

            import argparse
            _parser = argparse.ArgumentParser(prog='Write numbers', description='')
            _parser.add_argument("--start", dest="start", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--count", dest="count", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--numbers", dest="numbers_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = write_numbers(**_parsed_args)
          image: python:3.7
        - image: busybox
          name: copy-results-artifacts
          script: |
            #!/bin/sh
            set -exo pipefail
            TOTAL_SIZE=0
            ARTIFACT_SIZE=`wc -c $(workspaces.write-numbers.path)/artifacts/$(params.pipelineRun-name)/write-numbers/numbers | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.numbers.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              cp $(workspaces.write-numbers.path)/artifacts/$(params.pipelineRun-name)/write-numbers/numbers $(results.numbers.path)
            fi
          onError: continue
        results:
        - name: numbers
          description: /tmp/outputs/numbers/data
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": [{"if": {"cond": {"isPresent": "start"}, "then": ["--start",
              {"inputValue": "start"}]}}, {"if": {"cond": {"isPresent": "count"},
              "then": ["--count", {"inputValue": "count"}]}}, "--numbers", {"outputPath":
              "numbers"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
              \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import
              os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
              file_path\n\ndef write_numbers(\n        numbers_path, start = 0, count
              = 10):\n    with open(numbers_path, ''w'') as writer:\n        for i
              in range(start, count):\n            writer.write(str(i) + ''\\n'')\n\nimport
              argparse\n_parser = argparse.ArgumentParser(prog=''Write numbers'',
              description='''')\n_parser.add_argument(\"--start\", dest=\"start\",
              type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--count\",
              dest=\"count\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--numbers\",
              dest=\"numbers_path\", type=_make_parent_dirs_and_return_path, required=True,
              default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
              = write_numbers(**_parsed_args)\n"], "image": "python:3.7"}}, "inputs":
              [{"default": "0", "name": "start", "optional": true, "type": "Integer"},
              {"default": "10", "name": "count", "optional": true, "type": "Integer"}],
              "name": "Write numbers", "outputs": [{"name": "numbers", "type": "String"}]}'
            tekton.dev/template: ''
        workspaces:
        - name: write-numbers
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: write-numbers
        workspace: big-data-passing
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: print-text-4
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-4.path)/artifacts/$(params.pipelineRun-name)/write-numbers/numbers
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"description": "Print text",
              "implementation": {"container": {"args": ["--text", {"inputPath": "text"}],
              "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
              > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def print_text(\n        text_path\n):  #
              The \"text\" input is untyped so that any data can be printed\n    ''''''Print
              text''''''\n    with open(text_path, ''r'') as reader:\n        for
              line in reader:\n            print(line, end='''')\n\nimport argparse\n_parser
              = argparse.ArgumentParser(prog=''Print text'', description=''Print text'')\n_parser.add_argument(\"--text\",
              dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = print_text(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "text"}], "name": "Print
              text"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-4
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: print-text-4
        workspace: big-data-passing
      runAfter:
      - write-numbers
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: sum-numbers
      taskSpec:
        steps:
        - name: main
          args:
          - --numbers
          - $(workspaces.sum-numbers.path)/artifacts/$(params.pipelineRun-name)/write-numbers/numbers
          - '----output-paths'
          - $(workspaces.sum-numbers.path)/artifacts/$(params.pipelineRun-name)/sum-numbers/Output
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def sum_numbers(numbers_path):
                sum = 0
                with open(numbers_path, 'r') as reader:
                    for line in reader:
                        sum = sum + int(line)
                return sum

            def _serialize_int(int_value: int) -> str:
                if isinstance(int_value, str):
                    return int_value
                if not isinstance(int_value, int):
                    raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
                return str(int_value)

            import argparse
            _parser = argparse.ArgumentParser(prog='Sum numbers', description='')
            _parser.add_argument("--numbers", dest="numbers_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = sum_numbers(**_parsed_args)

            _outputs = [_outputs]

            _output_serializers = [
                _serialize_int,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
          image: python:3.7
        - image: busybox
          name: copy-results-artifacts
          script: |
            #!/bin/sh
            set -exo pipefail
            TOTAL_SIZE=0
            ARTIFACT_SIZE=`wc -c $(workspaces.sum-numbers.path)/artifacts/$(params.pipelineRun-name)/sum-numbers/Output | awk '{print $1}'`
            TOTAL_SIZE=$( expr $TOTAL_SIZE + $ARTIFACT_SIZE)
            touch $(results.output.path)
            if [[ $TOTAL_SIZE -lt 3072 ]]; then
              cp $(workspaces.sum-numbers.path)/artifacts/$(params.pipelineRun-name)/sum-numbers/Output $(results.output.path)
            fi
          onError: continue
        results:
        - name: output
          description: /tmp/outputs/Output/data
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["--numbers", {"inputPath": "numbers"}, "----output-paths",
              {"outputPath": "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
              \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def sum_numbers(numbers_path):\n    sum = 0\n    with open(numbers_path,
              ''r'') as reader:\n        for line in reader:\n            sum = sum
              + int(line)\n    return sum\n\ndef _serialize_int(int_value: int) ->
              str:\n    if isinstance(int_value, str):\n        return int_value\n    if
              not isinstance(int_value, int):\n        raise TypeError(''Value \"{}\"
              has type \"{}\" instead of int.''.format(str(int_value), str(type(int_value))))\n    return
              str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Sum
              numbers'', description='''')\n_parser.add_argument(\"--numbers\", dest=\"numbers_path\",
              type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = sum_numbers(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "numbers", "type": "String"}],
              "name": "Sum numbers", "outputs": [{"name": "Output", "type": "Integer"}]}'
            tekton.dev/template: ''
        workspaces:
        - name: sum-numbers
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: sum-numbers
        workspace: big-data-passing
      runAfter:
      - write-numbers
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: print-text-5
      taskSpec:
        steps:
        - name: main
          args:
          - --text
          - $(workspaces.print-text-5.path)/artifacts/$(params.pipelineRun-name)/sum-numbers/Output
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_text(
                    text_path
            ):  # The "text" input is untyped so that any data can be printed
                '''Print text'''
                with open(text_path, 'r') as reader:
                    for line in reader:
                        print(line, end='')

            import argparse
            _parser = argparse.ArgumentParser(prog='Print text', description='Print text')
            _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_text(**_parsed_args)
          image: python:3.7
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"description": "Print text",
              "implementation": {"container": {"args": ["--text", {"inputPath": "text"}],
              "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
              > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def print_text(\n        text_path\n):  #
              The \"text\" input is untyped so that any data can be printed\n    ''''''Print
              text''''''\n    with open(text_path, ''r'') as reader:\n        for
              line in reader:\n            print(line, end='''')\n\nimport argparse\n_parser
              = argparse.ArgumentParser(prog=''Print text'', description=''Print text'')\n_parser.add_argument(\"--text\",
              dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = print_text(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "text"}], "name": "Print
              text"}'
            tekton.dev/template: ''
        workspaces:
        - name: print-text-5
        params:
        - name: pipelineRun-name
      timeout: 0s
      workspaces:
      - name: print-text-5
        workspace: big-data-passing
      runAfter:
      - sum-numbers
      params:
      - name: pipelineRun-name
        value: $(context.pipelineRun.name)
    - name: gen-params
      taskSpec:
        steps:
        - name: main
          args:
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def gen_params():
                import random
                num = random.randint(0, 9)
                return num

            def _serialize_int(int_value: int) -> str:
                if isinstance(int_value, str):
                    return int_value
                if not isinstance(int_value, int):
                    raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
                return str(int_value)

            import argparse
            _parser = argparse.ArgumentParser(prog='Gen params', description='')
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = gen_params(**_parsed_args)

            _outputs = [_outputs]

            _output_serializers = [
                _serialize_int,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
          image: python:3.7
        results:
        - name: output
          description: /tmp/outputs/Output/data
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["----output-paths", {"outputPath": "Output"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def gen_params():\n    import random\n    num
              = random.randint(0, 9)\n    return num\n\ndef _serialize_int(int_value:
              int) -> str:\n    if isinstance(int_value, str):\n        return int_value\n    if
              not isinstance(int_value, int):\n        raise TypeError(''Value \"{}\"
              has type \"{}\" instead of int.''.format(str(int_value), str(type(int_value))))\n    return
              str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Gen
              params'', description='''')\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = gen_params(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "name": "Gen params", "outputs": [{"name":
              "Output", "type": "Integer"}]}'
            tekton.dev/template: ''
      timeout: 0s
    - name: print-params
      params:
      - name: gen-params-Output
        value: $(tasks.gen-params.results.output)
      taskSpec:
        steps:
        - name: main
          args:
          - --numbers-parm
          - $(inputs.params.gen-params-Output)
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def print_params(numbers_parm):
                print("The result number is: %d" % numbers_parm)

            import argparse
            _parser = argparse.ArgumentParser(prog='Print params', description='')
            _parser.add_argument("--numbers-parm", dest="numbers_parm", type=int, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = print_params(**_parsed_args)
          image: python:3.7
        params:
        - name: gen-params-Output
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["--numbers-parm", {"inputValue": "numbers_parm"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def print_params(numbers_parm):\n    print(\"The
              result number is: %d\" % numbers_parm)\n\nimport argparse\n_parser =
              argparse.ArgumentParser(prog=''Print params'', description='''')\n_parser.add_argument(\"--numbers-parm\",
              dest=\"numbers_parm\", type=int, required=True, default=argparse.SUPPRESS)\n_parsed_args
              = vars(_parser.parse_args())\n\n_outputs = print_params(**_parsed_args)\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "numbers_parm", "type":
              "Integer"}], "name": "Print params"}'
            tekton.dev/template: ''
      timeout: 0s
    workspaces:
    - name: big-data-passing
  timeout: 0s
  workspaces:
  - name: big-data-passing
    volumeClaimTemplate:
      spec:
        storageClassName: csi-s3
        accessModes:
        - ReadWriteMany
        resources:
          requests:
            storage: 2Gi
