# Copyright 2020 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"name": "Parallelfor item argument resolving"}'
    sidecar.istio.io/inject: 'false'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"consume": [], "consume-2": [], "consume-3": [],
      "consume-4": [], "consume-5": [], "consume-6": [], "consume-7": [], "produce-list-of-dicts":
      [["Output", "$(results.output.path)"]], "produce-list-of-ints": [["Output",
      "$(results.output.path)"]], "produce-list-of-strings": [["Output", "$(results.output.path)"]],
      "produce-str": [["Output", "$(results.output.path)"]]}'
    tekton.dev/input_artifacts: '{"consume": [{"name": "produce-list-of-strings-Output",
      "parent_task": "produce-list-of-strings"}], "consume-3": [{"name": "produce-str-Output",
      "parent_task": "produce-str"}], "consume-4": [{"name": "produce-list-of-ints-Output",
      "parent_task": "produce-list-of-ints"}], "consume-6": [{"name": "produce-list-of-dicts-Output",
      "parent_task": "produce-list-of-dicts"}]}'
    tekton.dev/output_artifacts: '{"produce-list-of-dicts": [{"key": "artifacts/$PIPELINERUN/produce-list-of-dicts/Output.tgz",
      "name": "produce-list-of-dicts-Output", "path": "/tmp/outputs/Output/data"}],
      "produce-list-of-ints": [{"key": "artifacts/$PIPELINERUN/produce-list-of-ints/Output.tgz",
      "name": "produce-list-of-ints-Output", "path": "/tmp/outputs/Output/data"}],
      "produce-list-of-strings": [{"key": "artifacts/$PIPELINERUN/produce-list-of-strings/Output.tgz",
      "name": "produce-list-of-strings-Output", "path": "/tmp/outputs/Output/data"}],
      "produce-str": [{"key": "artifacts/$PIPELINERUN/produce-str/Output.tgz", "name":
      "produce-str-Output", "path": "/tmp/outputs/Output/data"}]}'
  name: parallelfor-item-argument-resolving
spec:
  pipelineSpec:
    tasks:
    - name: produce-str
      taskSpec:
        metadata:
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["----output-paths", {"outputPath": "Output"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def produce_str():\n    return \"Hello\"\n\ndef
              _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value,
              str):\n        raise TypeError(''Value \"{}\" has type \"{}\" instead
              of str.''.format(str(str_value), str(type(str_value))))\n    return
              str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Produce
              str'', description='''')\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_str(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "name": "Produce str", "outputs": [{"name":
              "Output", "type": "String"}]}'
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - 'program_path=$(mktemp)

            printf "%s" "$0" > "$program_path"

            python3 -u "$program_path" "$@"

            '
          - "def produce_str():\n    return \"Hello\"\n\ndef _serialize_str(str_value:\
            \ str) -> str:\n    if not isinstance(str_value, str):\n        raise\
            \ TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(str(str_value),\
            \ str(type(str_value))))\n    return str_value\n\nimport argparse\n_parser\
            \ = argparse.ArgumentParser(prog='Produce str', description='')\n_parser.add_argument(\"\
            ----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = produce_str(**_parsed_args)\n\n_outputs = [_outputs]\n\
            \n_output_serializers = [\n    _serialize_str,\n\n]\n\nimport os\nfor\
            \ idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
            \    except OSError:\n        pass\n    with open(output_file, 'w') as\
            \ f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: python:3.7
          name: main
      timeout: 0s
    - name: produce-list-of-strings
      taskSpec:
        metadata:
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["----output-paths", {"outputPath": "Output"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def produce_list_of_strings():\n    return
              (\"a\", \"z\")\n\ndef _serialize_json(obj) -> str:\n    if isinstance(obj,
              str):\n        return obj\n    import json\n    def default_serializer(obj):\n        if
              hasattr(obj, ''to_struct''):\n            return obj.to_struct()\n        else:\n            raise
              TypeError(\"Object of type ''%s'' is not JSON serializable and does
              not have .to_struct() method.\" % obj.__class__.__name__)\n    return
              json.dumps(obj, default=default_serializer, sort_keys=True)\n\nimport
              argparse\n_parser = argparse.ArgumentParser(prog=''Produce list of strings'',
              description='''')\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\",
              type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_list_of_strings(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "name": "Produce list of strings", "outputs":
              [{"name": "Output", "type": "JsonArray"}]}'
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - 'program_path=$(mktemp)

            printf "%s" "$0" > "$program_path"

            python3 -u "$program_path" "$@"

            '
          - "def produce_list_of_strings():\n    return (\"a\", \"z\")\n\ndef _serialize_json(obj)\
            \ -> str:\n    if isinstance(obj, str):\n        return obj\n    import\
            \ json\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n\
            \            return obj.to_struct()\n        else:\n            raise\
            \ TypeError(\"Object of type '%s' is not JSON serializable and does not\
            \ have .to_struct() method.\" % obj.__class__.__name__)\n    return json.dumps(obj,\
            \ default=default_serializer, sort_keys=True)\n\nimport argparse\n_parser\
            \ = argparse.ArgumentParser(prog='Produce list of strings', description='')\n\
            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
            \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files =\
            \ _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_list_of_strings(**_parsed_args)\n\
            \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\
            \n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: python:3.7
          name: main
      timeout: 0s
    - name: produce-list-of-ints
      taskSpec:
        metadata:
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["----output-paths", {"outputPath": "Output"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def produce_list_of_ints():\n    return
              (1234567890, 987654321)\n\ndef _serialize_json(obj) -> str:\n    if
              isinstance(obj, str):\n        return obj\n    import json\n    def
              default_serializer(obj):\n        if hasattr(obj, ''to_struct''):\n            return
              obj.to_struct()\n        else:\n            raise TypeError(\"Object
              of type ''%s'' is not JSON serializable and does not have .to_struct()
              method.\" % obj.__class__.__name__)\n    return json.dumps(obj, default=default_serializer,
              sort_keys=True)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Produce
              list of ints'', description='''')\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_list_of_ints(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "name": "Produce list of ints", "outputs":
              [{"name": "Output", "type": "JsonArray"}]}'
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - 'program_path=$(mktemp)

            printf "%s" "$0" > "$program_path"

            python3 -u "$program_path" "$@"

            '
          - "def produce_list_of_ints():\n    return (1234567890, 987654321)\n\ndef\
            \ _serialize_json(obj) -> str:\n    if isinstance(obj, str):\n       \
            \ return obj\n    import json\n    def default_serializer(obj):\n    \
            \    if hasattr(obj, 'to_struct'):\n            return obj.to_struct()\n\
            \        else:\n            raise TypeError(\"Object of type '%s' is not\
            \ JSON serializable and does not have .to_struct() method.\" % obj.__class__.__name__)\n\
            \    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\
            \nimport argparse\n_parser = argparse.ArgumentParser(prog='Produce list\
            \ of ints', description='')\n_parser.add_argument(\"----output-paths\"\
            , dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
            _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs =\
            \ produce_list_of_ints(**_parsed_args)\n\n_outputs = [_outputs]\n\n_output_serializers\
            \ = [\n    _serialize_json,\n\n]\n\nimport os\nfor idx, output_file in\
            \ enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
            \    except OSError:\n        pass\n    with open(output_file, 'w') as\
            \ f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: python:3.7
          name: main
      timeout: 0s
    - name: produce-list-of-dicts
      taskSpec:
        metadata:
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["----output-paths", {"outputPath": "Output"}], "command":
              ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
              -u \"$program_path\" \"$@\"\n", "def produce_list_of_dicts():\n    return
              ({\"aaa\": \"aaa1\", \"bbb\": \"bbb1\"}, {\"aaa\": \"aaa2\", \"bbb\":
              \"bbb2\"})\n\ndef _serialize_json(obj) -> str:\n    if isinstance(obj,
              str):\n        return obj\n    import json\n    def default_serializer(obj):\n        if
              hasattr(obj, ''to_struct''):\n            return obj.to_struct()\n        else:\n            raise
              TypeError(\"Object of type ''%s'' is not JSON serializable and does
              not have .to_struct() method.\" % obj.__class__.__name__)\n    return
              json.dumps(obj, default=default_serializer, sort_keys=True)\n\nimport
              argparse\n_parser = argparse.ArgumentParser(prog=''Produce list of dicts'',
              description='''')\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\",
              type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_list_of_dicts(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "name": "Produce list of dicts", "outputs":
              [{"name": "Output", "type": "JsonArray"}]}'
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - 'program_path=$(mktemp)

            printf "%s" "$0" > "$program_path"

            python3 -u "$program_path" "$@"

            '
          - "def produce_list_of_dicts():\n    return ({\"aaa\": \"aaa1\", \"bbb\"\
            : \"bbb1\"}, {\"aaa\": \"aaa2\", \"bbb\": \"bbb2\"})\n\ndef _serialize_json(obj)\
            \ -> str:\n    if isinstance(obj, str):\n        return obj\n    import\
            \ json\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n\
            \            return obj.to_struct()\n        else:\n            raise\
            \ TypeError(\"Object of type '%s' is not JSON serializable and does not\
            \ have .to_struct() method.\" % obj.__class__.__name__)\n    return json.dumps(obj,\
            \ default=default_serializer, sort_keys=True)\n\nimport argparse\n_parser\
            \ = argparse.ArgumentParser(prog='Produce list of dicts', description='')\n\
            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
            \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files =\
            \ _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_list_of_dicts(**_parsed_args)\n\
            \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\
            \n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: python:3.7
          name: main
      timeout: 0s
    - name: for-loop-1
      params:
      - name: produce-list-of-strings-Output
        value: $(tasks.produce-list-of-strings.results.output)
      - name: produce-list-of-strings-Output-loop-item
        value: $(tasks.produce-list-of-strings.results.output)
      - name: produce-str-Output
        value: $(tasks.produce-str.results.output)
      runAfter:
      - produce-list-of-strings
      - produce-str
      taskRef:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        name: for-loop-1
    - name: for-loop-2
      params:
      - name: produce-list-of-ints-Output
        value: $(tasks.produce-list-of-ints.results.output)
      - name: produce-list-of-ints-Output-loop-item
        value: $(tasks.produce-list-of-ints.results.output)
      runAfter:
      - produce-list-of-ints
      taskRef:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        name: for-loop-2
    - name: for-loop-3
      params:
      - name: produce-list-of-dicts-Output
        value: $(tasks.produce-list-of-dicts.results.output)
      - name: produce-list-of-dicts-Output-loop-item
        value: $(tasks.produce-list-of-dicts.results.output)
      runAfter:
      - produce-list-of-dicts
      taskRef:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        name: for-loop-3
  timeout: 0s
