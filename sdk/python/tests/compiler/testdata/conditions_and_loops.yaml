# Copyright 2021 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "3", "name": "n",
      "optional": true}, {"default": "20", "name": "threshold", "optional": true}],
      "name": "Conditions and loops"}'
    sidecar.istio.io/inject: 'false'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"add-numbers": [["Output", "$(results.output.path)"]],
      "notify-failure": [], "notify-success": [], "print-number": [["Output", "$(results.output.path)"]],
      "produce-numbers": [["Output", "$(results.output.path)"]]}'
    tekton.dev/input_artifacts: '{"print-number": [{"name": "add-numbers-Output",
      "parent_task": "add-numbers"}]}'
    tekton.dev/output_artifacts: '{"add-numbers": [{"key": "artifacts/$PIPELINERUN/add-numbers/Output.tgz",
      "name": "add-numbers-Output", "path": "/tmp/outputs/Output/data"}], "print-number":
      [{"key": "artifacts/$PIPELINERUN/print-number/Output.tgz", "name": "print-number-Output",
      "path": "/tmp/outputs/Output/data"}], "produce-numbers": [{"key": "artifacts/$PIPELINERUN/produce-numbers/Output.tgz",
      "name": "produce-numbers-Output", "path": "/tmp/outputs/Output/data"}]}'
  name: conditions-and-loops
spec:
  params:
  - name: n
    value: '3'
  - name: threshold
    value: '20'
  pipelineSpec:
    params:
    - default: '3'
      name: n
    - default: '20'
      name: threshold
    tasks:
    - name: produce-numbers
      params:
      - name: n
        value: $(params.n)
      taskSpec:
        metadata:
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["--n", {"inputValue": "n"}, "----output-paths", {"outputPath":
              "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
              \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def produce_numbers(n):\n    import random\n    rl = random.sample(range(0,
              1000), n)\n    print(rl)\n    return rl\n\ndef _serialize_json(obj)
              -> str:\n    if isinstance(obj, str):\n        return obj\n    import
              json\n    def default_serializer(obj):\n        if hasattr(obj, ''to_struct''):\n            return
              obj.to_struct()\n        else:\n            raise TypeError(\"Object
              of type ''%s'' is not JSON serializable and does not have .to_struct()
              method.\" % obj.__class__.__name__)\n    return json.dumps(obj, default=default_serializer,
              sort_keys=True)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Produce
              numbers'', description='''')\n_parser.add_argument(\"--n\", dest=\"n\",
              type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_numbers(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "n", "type": "Integer"}],
              "name": "Produce numbers", "outputs": [{"name": "Output", "type": "JsonArray"}]}'
            tekton.dev/template: ''
          labels:
            pipelines.kubeflow.org/cache_enabled: 'true'
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/pipelinename: ''
        params:
        - name: n
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - --n
          - $(inputs.params.n)
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - 'program_path=$(mktemp)

            printf "%s" "$0" > "$program_path"

            python3 -u "$program_path" "$@"

            '
          - "def produce_numbers(n):\n    import random\n    rl = random.sample(range(0,\
            \ 1000), n)\n    print(rl)\n    return rl\n\ndef _serialize_json(obj)\
            \ -> str:\n    if isinstance(obj, str):\n        return obj\n    import\
            \ json\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n\
            \            return obj.to_struct()\n        else:\n            raise\
            \ TypeError(\"Object of type '%s' is not JSON serializable and does not\
            \ have .to_struct() method.\" % obj.__class__.__name__)\n    return json.dumps(obj,\
            \ default=default_serializer, sort_keys=True)\n\nimport argparse\n_parser\
            \ = argparse.ArgumentParser(prog='Produce numbers', description='')\n\
            _parser.add_argument(\"--n\", dest=\"n\", type=int, required=True, default=argparse.SUPPRESS)\n\
            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
            \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files =\
            \ _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_numbers(**_parsed_args)\n\
            \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\
            \n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: python:3.7
          name: main
      timeout: 0s
    - name: conditions-and-loops-for-loop-1
      params:
      - name: produce-numbers-Output-loop-item
        value: $(tasks.produce-numbers.results.output)
      - name: threshold
        value: $(params.threshold)
      runAfter:
      - produce-numbers
      taskSpec:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        spec:
          iterateParam: produce-numbers-Output-loop-item
          pipelineSpec:
            params:
            - name: produce-numbers-Output-loop-item
              type: string
            - name: threshold
              type: string
            tasks:
            - name: add-numbers
              params:
              - name: produce-numbers-Output-loop-item
                value: $(params.produce-numbers-Output-loop-item)
              taskSpec:
                metadata:
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": ["--a", {"inputValue": "a"}, "--b", {"inputValue":
                      "b"}, "----output-paths", {"outputPath": "Output"}], "command":
                      ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
                      > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
                      "def add_numbers(a, b):\n    print(a + b)\n    return a + b\n\ndef
                      _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,
                      str):\n        return int_value\n    if not isinstance(int_value,
                      int):\n        raise TypeError(''Value \"{}\" has type \"{}\"
                      instead of int.''.format(str(int_value), str(type(int_value))))\n    return
                      str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Add
                      numbers'', description='''')\n_parser.add_argument(\"--a\",
                      dest=\"a\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--b\",
                      dest=\"b\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
                      dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
                      = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = add_numbers(**_parsed_args)\n\n_outputs
                      = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport
                      os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
                      OSError:\n        pass\n    with open(output_file, ''w'') as
                      f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
                      "image": "python:3.7"}}, "inputs": [{"name": "a", "type": "Integer"},
                      {"name": "b", "type": "Integer"}], "name": "Add numbers", "outputs":
                      [{"name": "Output", "type": "Integer"}]}'
                    tekton.dev/template: ''
                  labels:
                    pipelines.kubeflow.org/cache_enabled: 'true'
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/pipelinename: ''
                params:
                - name: produce-numbers-Output-loop-item
                  type: string
                results:
                - description: /tmp/outputs/Output/data
                  name: output
                steps:
                - args:
                  - --a
                  - $(inputs.params.produce-numbers-Output-loop-item)
                  - --b
                  - '10'
                  - '----output-paths'
                  - $(results.output.path)
                  command:
                  - sh
                  - -ec
                  - 'program_path=$(mktemp)

                    printf "%s" "$0" > "$program_path"

                    python3 -u "$program_path" "$@"

                    '
                  - "def add_numbers(a, b):\n    print(a + b)\n    return a + b\n\n\
                    def _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,\
                    \ str):\n        return int_value\n    if not isinstance(int_value,\
                    \ int):\n        raise TypeError('Value \"{}\" has type \"{}\"\
                    \ instead of int.'.format(str(int_value), str(type(int_value))))\n\
                    \    return str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Add\
                    \ numbers', description='')\n_parser.add_argument(\"--a\", dest=\"\
                    a\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
                    --b\", dest=\"b\", type=int, required=True, default=argparse.SUPPRESS)\n\
                    _parser.add_argument(\"----output-paths\", dest=\"_output_paths\"\
                    , type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
                    _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs\
                    \ = add_numbers(**_parsed_args)\n\n_outputs = [_outputs]\n\n_output_serializers\
                    \ = [\n    _serialize_int,\n\n]\n\nimport os\nfor idx, output_file\
                    \ in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
                    \    except OSError:\n        pass\n    with open(output_file,\
                    \ 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
                  image: python:3.7
                  name: main
              timeout: 0s
            - name: print-number
              params:
              - name: add-numbers-Output
                value: $(tasks.add-numbers.results.output)
              taskSpec:
                metadata:
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": ["--a", {"inputValue": "a"}, "----output-paths", {"outputPath":
                      "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
                      \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\"
                      \"$@\"\n", "def print_number(a):\n    print(a)\n    return a\n\ndef
                      _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,
                      str):\n        return int_value\n    if not isinstance(int_value,
                      int):\n        raise TypeError(''Value \"{}\" has type \"{}\"
                      instead of int.''.format(str(int_value), str(type(int_value))))\n    return
                      str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Print
                      number'', description='''')\n_parser.add_argument(\"--a\", dest=\"a\",
                      type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
                      dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
                      = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = print_number(**_parsed_args)\n\n_outputs
                      = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport
                      os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
                      OSError:\n        pass\n    with open(output_file, ''w'') as
                      f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
                      "image": "python:3.7"}}, "inputs": [{"name": "a", "type": "Integer"}],
                      "name": "Print number", "outputs": [{"name": "Output", "type":
                      "Integer"}]}'
                    tekton.dev/template: ''
                  labels:
                    pipelines.kubeflow.org/cache_enabled: 'true'
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/pipelinename: ''
                params:
                - name: add-numbers-Output
                  type: string
                results:
                - description: /tmp/outputs/Output/data
                  name: output
                steps:
                - args:
                  - --a
                  - $(inputs.params.add-numbers-Output)
                  - '----output-paths'
                  - $(results.output.path)
                  command:
                  - sh
                  - -ec
                  - 'program_path=$(mktemp)

                    printf "%s" "$0" > "$program_path"

                    python3 -u "$program_path" "$@"

                    '
                  - "def print_number(a):\n    print(a)\n    return a\n\ndef _serialize_int(int_value:\
                    \ int) -> str:\n    if isinstance(int_value, str):\n        return\
                    \ int_value\n    if not isinstance(int_value, int):\n        raise\
                    \ TypeError('Value \"{}\" has type \"{}\" instead of int.'.format(str(int_value),\
                    \ str(type(int_value))))\n    return str(int_value)\n\nimport\
                    \ argparse\n_parser = argparse.ArgumentParser(prog='Print number',\
                    \ description='')\n_parser.add_argument(\"--a\", dest=\"a\", type=int,\
                    \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
                    ----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n\
                    _parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
                    _output_paths\", [])\n\n_outputs = print_number(**_parsed_args)\n\
                    \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\
                    \n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
                    \    try:\n        os.makedirs(os.path.dirname(output_file))\n\
                    \    except OSError:\n        pass\n    with open(output_file,\
                    \ 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
                  image: python:3.7
                  name: main
              timeout: 0s
            - name: notify-success
              taskSpec:
                metadata:
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": [], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
                      \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\"
                      \"$@\"\n", "def notify_success():\n    print(''SUCCESS!'')\n\nimport
                      argparse\n_parser = argparse.ArgumentParser(prog=''Notify success'',
                      description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
                      = notify_success(**_parsed_args)\n"], "image": "python:3.7"}},
                      "name": "Notify success"}'
                    tekton.dev/template: ''
                  labels:
                    pipelines.kubeflow.org/cache_enabled: 'true'
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/pipelinename: ''
                steps:
                - command:
                  - sh
                  - -ec
                  - 'program_path=$(mktemp)

                    printf "%s" "$0" > "$program_path"

                    python3 -u "$program_path" "$@"

                    '
                  - "def notify_success():\n    print('SUCCESS!')\n\nimport argparse\n\
                    _parser = argparse.ArgumentParser(prog='Notify success', description='')\n\
                    _parsed_args = vars(_parser.parse_args())\n\n_outputs = notify_success(**_parsed_args)\n"
                  image: python:3.7
                  name: main
              timeout: 0s
              when:
              - input: $(tasks.condition-2.results.outcome)
                operator: in
                values:
                - 'true'
            - name: notify-failure
              taskSpec:
                metadata:
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": [], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
                      \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\"
                      \"$@\"\n", "def notify_failure():\n    print(''FAILED!'')\n\nimport
                      argparse\n_parser = argparse.ArgumentParser(prog=''Notify failure'',
                      description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
                      = notify_failure(**_parsed_args)\n"], "image": "python:3.7"}},
                      "name": "Notify failure"}'
                    tekton.dev/template: ''
                  labels:
                    pipelines.kubeflow.org/cache_enabled: 'true'
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/pipelinename: ''
                steps:
                - command:
                  - sh
                  - -ec
                  - 'program_path=$(mktemp)

                    printf "%s" "$0" > "$program_path"

                    python3 -u "$program_path" "$@"

                    '
                  - "def notify_failure():\n    print('FAILED!')\n\nimport argparse\n\
                    _parser = argparse.ArgumentParser(prog='Notify failure', description='')\n\
                    _parsed_args = vars(_parser.parse_args())\n\n_outputs = notify_failure(**_parsed_args)\n"
                  image: python:3.7
                  name: main
              timeout: 0s
              when:
              - input: $(tasks.condition-3.results.outcome)
                operator: in
                values:
                - 'true'
            - name: condition-2
              params:
              - name: operand1
                value: $(tasks.print-number.results.output)
              - name: operand2
                value: $(params.threshold)
              - name: operator
                value: '>'
              taskSpec:
                params:
                - name: operand1
                  type: string
                - name: operand2
                  type: string
                - name: operator
                  type: string
                results:
                - description: Conditional task outcome
                  name: outcome
                steps:
                - image: python:alpine3.6
                  script: "python -c 'import sys\ninput1=str.rstrip(sys.argv[1])\n\
                    input2=str.rstrip(sys.argv[2])\ntry:\n  input1=int(input1)\n \
                    \ input2=int(input2)\nexcept:\n  input1=str(input1)\noutcome=\"\
                    true\" if (input1 $(inputs.params.operator) input2) else \"false\"\
                    \nf = open(\"/tekton/results/outcome\", \"w\")\nf.write(outcome)\n\
                    f.close()' '$(inputs.params.operand1)' '$(inputs.params.operand2)'"
            - name: condition-3
              params:
              - name: operand1
                value: $(tasks.print-number.results.output)
              - name: operand2
                value: $(params.threshold)
              - name: operator
                value: <=
              taskSpec:
                params:
                - name: operand1
                  type: string
                - name: operand2
                  type: string
                - name: operator
                  type: string
                results:
                - description: Conditional task outcome
                  name: outcome
                steps:
                - image: python:alpine3.6
                  script: "python -c 'import sys\ninput1=str.rstrip(sys.argv[1])\n\
                    input2=str.rstrip(sys.argv[2])\ntry:\n  input1=int(input1)\n \
                    \ input2=int(input2)\nexcept:\n  input1=str(input1)\noutcome=\"\
                    true\" if (input1 $(inputs.params.operator) input2) else \"false\"\
                    \nf = open(\"/tekton/results/outcome\", \"w\")\nf.write(outcome)\n\
                    f.close()' '$(inputs.params.operand1)' '$(inputs.params.operand2)'"
  timeout: 0s
