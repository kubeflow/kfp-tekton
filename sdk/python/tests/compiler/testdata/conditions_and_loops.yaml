# Copyright 2020 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "3", "name": "n",
      "optional": true}, {"default": "20", "name": "threshold", "optional": true}],
      "name": "Conditions and loops"}'
    sidecar.istio.io/inject: 'false'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"add-numbers": [["Output", "$(results.output.path)"]],
      "notify-failure": [], "notify-success": [], "print-number": [["Output", "$(results.output.path)"]],
      "produce-numbers": [["Output", "$(results.output.path)"]]}'
    tekton.dev/input_artifacts: '{"print-number": [{"name": "add-numbers-Output",
      "parent_task": "add-numbers"}]}'
    tekton.dev/output_artifacts: '{"add-numbers": [{"key": "artifacts/$PIPELINERUN/add-numbers/Output.tgz",
      "name": "add-numbers-Output", "path": "/tmp/outputs/Output/data"}], "print-number":
      [{"key": "artifacts/$PIPELINERUN/print-number/Output.tgz", "name": "print-number-Output",
      "path": "/tmp/outputs/Output/data"}], "produce-numbers": [{"key": "artifacts/$PIPELINERUN/produce-numbers/Output.tgz",
      "name": "produce-numbers-Output", "path": "/tmp/outputs/Output/data"}]}'
  name: conditions-and-loops
spec:
  params:
  - name: n
    value: '3'
  - name: threshold
    value: '20'
  pipelineSpec:
    params:
    - default: '3'
      name: n
    - default: '20'
      name: threshold
    tasks:
    - name: produce-numbers
      params:
      - name: n
        value: $(params.n)
      taskSpec:
        metadata:
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["--n", {"inputValue": "n"}, "----output-paths", {"outputPath":
              "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
              \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def produce_numbers(n):\n    import random\n    rl = random.sample(range(0,
              1000), n)\n    print(rl)\n    return rl\n\ndef _serialize_json(obj)
              -> str:\n    if isinstance(obj, str):\n        return obj\n    import
              json\n    def default_serializer(obj):\n        if hasattr(obj, ''to_struct''):\n            return
              obj.to_struct()\n        else:\n            raise TypeError(\"Object
              of type ''%s'' is not JSON serializable and does not have .to_struct()
              method.\" % obj.__class__.__name__)\n    return json.dumps(obj, default=default_serializer,
              sort_keys=True)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Produce
              numbers'', description='''')\n_parser.add_argument(\"--n\", dest=\"n\",
              type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_numbers(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "n", "type": "Integer"}],
              "name": "Produce numbers", "outputs": [{"name": "Output", "type": "JsonArray"}]}'
        params:
        - name: n
        results:
        - description: /tmp/outputs/Output/data
          name: output
        steps:
        - args:
          - --n
          - $(inputs.params.n)
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - 'program_path=$(mktemp)

            printf "%s" "$0" > "$program_path"

            python3 -u "$program_path" "$@"

            '
          - "def produce_numbers(n):\n    import random\n    rl = random.sample(range(0,\
            \ 1000), n)\n    print(rl)\n    return rl\n\ndef _serialize_json(obj)\
            \ -> str:\n    if isinstance(obj, str):\n        return obj\n    import\
            \ json\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n\
            \            return obj.to_struct()\n        else:\n            raise\
            \ TypeError(\"Object of type '%s' is not JSON serializable and does not\
            \ have .to_struct() method.\" % obj.__class__.__name__)\n    return json.dumps(obj,\
            \ default=default_serializer, sort_keys=True)\n\nimport argparse\n_parser\
            \ = argparse.ArgumentParser(prog='Produce numbers', description='')\n\
            _parser.add_argument(\"--n\", dest=\"n\", type=int, required=True, default=argparse.SUPPRESS)\n\
            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
            \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files =\
            \ _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_numbers(**_parsed_args)\n\
            \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\
            \n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: python:3.7
          name: main
      timeout: 0s
    - name: for-loop-1
      params:
      - name: produce-numbers-Output-loop-item
        value: $(tasks.produce-numbers.results.output)
      - name: threshold
        value: $(params.threshold)
      runAfter:
      - produce-numbers
      taskRef:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        name: for-loop-1
  timeout: 0s
