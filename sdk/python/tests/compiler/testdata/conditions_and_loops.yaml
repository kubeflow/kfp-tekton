# Copyright 2021 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: conditions-and-loops
  annotations:
    tekton.dev/output_artifacts: '{"add-numbers": [{"key": "artifacts/$PIPELINERUN/add-numbers/Output.tgz",
      "name": "add-numbers-Output", "path": "/tmp/outputs/Output/data"}], "print-number":
      [{"key": "artifacts/$PIPELINERUN/print-number/Output.tgz", "name": "print-number-Output",
      "path": "/tmp/outputs/Output/data"}], "produce-numbers": [{"key": "artifacts/$PIPELINERUN/produce-numbers/Output.tgz",
      "name": "produce-numbers-Output", "path": "/tmp/outputs/Output/data"}]}'
    tekton.dev/input_artifacts: '{"print-number": [{"name": "add-numbers-Output",
      "parent_task": "add-numbers"}]}'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"add-numbers": [["Output", "$(results.output.path)"]],
      "notify-failure": [], "notify-success": [], "print-number": [["Output", "$(results.output.path)"]],
      "produce-numbers": [["Output", "$(results.output.path)"]]}'
    sidecar.istio.io/inject: "false"
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "3", "name": "n",
      "optional": true}, {"default": "20", "name": "threshold", "optional": true}],
      "name": "Conditions and loops"}'
spec:
  params:
  - name: "n"
    value: '3'
  - {name: threshold, value: '20'}
  pipelineSpec:
    params:
    - name: "n"
      default: '3'
    - {name: threshold, default: '20'}
    tasks:
    - name: produce-numbers
      params:
      - name: "n"
        value: $(params.n)
      taskSpec:
        steps:
        - name: main
          args: [--n, $(inputs.params.n), '----output-paths', $(results.output.path)]
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            echo -n "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def produce_numbers(n):
                import random
                rl = random.sample(range(0, 1000), n)
                print(rl)
                return rl

            def _serialize_json(obj) -> str:
                if isinstance(obj, str):
                    return obj
                import json
                def default_serializer(obj):
                    if hasattr(obj, 'to_struct'):
                        return obj.to_struct()
                    else:
                        raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
                return json.dumps(obj, default=default_serializer, sort_keys=True)

            import argparse
            _parser = argparse.ArgumentParser(prog='Produce numbers', description='')
            _parser.add_argument("--n", dest="n", type=int, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = produce_numbers(**_parsed_args)

            _outputs = [_outputs]

            _output_serializers = [
                _serialize_json,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
          image: python:3.7
        params:
        - name: "n"
        results:
        - {name: output, description: /tmp/outputs/Output/data}
        metadata:
          annotations: {pipelines.kubeflow.org/component_spec: '{"implementation":
              {"container": {"args": ["--n", {"inputValue": "n"}, "----output-paths",
              {"outputPath": "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\necho
              -n \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def produce_numbers(n):\n    import random\n    rl = random.sample(range(0,
              1000), n)\n    print(rl)\n    return rl\n\ndef _serialize_json(obj)
              -> str:\n    if isinstance(obj, str):\n        return obj\n    import
              json\n    def default_serializer(obj):\n        if hasattr(obj, ''to_struct''):\n            return
              obj.to_struct()\n        else:\n            raise TypeError(\"Object
              of type ''%s'' is not JSON serializable and does not have .to_struct()
              method.\" % obj.__class__.__name__)\n    return json.dumps(obj, default=default_serializer,
              sort_keys=True)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Produce
              numbers'', description='''')\n_parser.add_argument(\"--n\", dest=\"n\",
              type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_numbers(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "n", "type": "Integer"}],
              "name": "Produce numbers", "outputs": [{"name": "Output", "type": "JsonArray"}]}'}
      timeout: 0s
    - runAfter: [produce-numbers]
      name: with-item-name-1
      taskRef: {apiVersion: custom.tekton.dev/v1alpha1, kind: PipelineLoop, name: with-item-name-1}
      params:
      - {name: produce-numbers-Output-loop-item, value: $(tasks.produce-numbers.results.output)}
      - {name: threshold, value: $(params.threshold)}
  timeout: 0s
