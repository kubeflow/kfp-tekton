# Copyright 2021 kubeflow.org
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: conditions-and-loops
  annotations:
    tekton.dev/output_artifacts: '{"add-numbers": [{"key": "artifacts/$PIPELINERUN/add-numbers/Output.tgz",
      "name": "add-numbers-Output", "path": "/tmp/outputs/Output/data"}], "print-number":
      [{"key": "artifacts/$PIPELINERUN/print-number/Output.tgz", "name": "print-number-Output",
      "path": "/tmp/outputs/Output/data"}], "produce-numbers": [{"key": "artifacts/$PIPELINERUN/produce-numbers/Output.tgz",
      "name": "produce-numbers-Output", "path": "/tmp/outputs/Output/data"}]}'
    tekton.dev/input_artifacts: '{"print-number": [{"name": "add-numbers-Output",
      "parent_task": "add-numbers"}]}'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"add-numbers": [["Output", "$(results.output.path)"]],
      "notify-failure": [], "notify-success": [], "print-number": [["Output", "$(results.output.path)"]],
      "produce-numbers": [["Output", "$(results.output.path)"]]}'
    sidecar.istio.io/inject: "false"
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "3", "name": "n",
      "optional": true, "type": "Integer"}, {"default": "20", "name": "threshold",
      "optional": true, "type": "Integer"}], "name": "conditions-and-loops"}'
spec:
  params:
  - name: "n"
    value: '3'
  - name: threshold
    value: '20'
  pipelineSpec:
    params:
    - name: "n"
      default: '3'
    - name: threshold
      default: '20'
    tasks:
    - name: produce-numbers
      params:
      - name: "n"
        value: $(params.n)
      taskSpec:
        steps:
        - name: main
          args:
          - --n
          - $(inputs.params.n)
          - '----output-paths'
          - $(results.output.path)
          command:
          - sh
          - -ec
          - |
            program_path=$(mktemp)
            printf "%s" "$0" > "$program_path"
            python3 -u "$program_path" "$@"
          - |
            def produce_numbers(n):
                import random
                rl = random.sample(range(0, 1000), n)
                print(rl)
                return rl

            def _serialize_json(obj) -> str:
                if isinstance(obj, str):
                    return obj
                import json
                def default_serializer(obj):
                    if hasattr(obj, 'to_struct'):
                        return obj.to_struct()
                    else:
                        raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
                return json.dumps(obj, default=default_serializer, sort_keys=True)

            import argparse
            _parser = argparse.ArgumentParser(prog='Produce numbers', description='')
            _parser.add_argument("--n", dest="n", type=int, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
            _parsed_args = vars(_parser.parse_args())
            _output_files = _parsed_args.pop("_output_paths", [])

            _outputs = produce_numbers(**_parsed_args)

            _outputs = [_outputs]

            _output_serializers = [
                _serialize_json,

            ]

            import os
            for idx, output_file in enumerate(_output_files):
                try:
                    os.makedirs(os.path.dirname(output_file))
                except OSError:
                    pass
                with open(output_file, 'w') as f:
                    f.write(_output_serializers[idx](_outputs[idx]))
          image: python:3.7
        params:
        - name: "n"
        results:
        - name: output
          description: /tmp/outputs/Output/data
        metadata:
          labels:
            pipelines.kubeflow.org/pipelinename: ''
            pipelines.kubeflow.org/generation: ''
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
              {"args": ["--n", {"inputValue": "n"}, "----output-paths", {"outputPath":
              "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
              \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "def produce_numbers(n):\n    import random\n    rl = random.sample(range(0,
              1000), n)\n    print(rl)\n    return rl\n\ndef _serialize_json(obj)
              -> str:\n    if isinstance(obj, str):\n        return obj\n    import
              json\n    def default_serializer(obj):\n        if hasattr(obj, ''to_struct''):\n            return
              obj.to_struct()\n        else:\n            raise TypeError(\"Object
              of type ''%s'' is not JSON serializable and does not have .to_struct()
              method.\" % obj.__class__.__name__)\n    return json.dumps(obj, default=default_serializer,
              sort_keys=True)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Produce
              numbers'', description='''')\n_parser.add_argument(\"--n\", dest=\"n\",
              type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
              dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
              = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_numbers(**_parsed_args)\n\n_outputs
              = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport
              os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
              OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
              "image": "python:3.7"}}, "inputs": [{"name": "n", "type": "Integer"}],
              "name": "Produce numbers", "outputs": [{"name": "Output", "type": "JsonArray"}]}'
            tekton.dev/template: ''
      timeout: 525600m
    - runAfter:
      - produce-numbers
      name: conditions-and-loops-for-loop-1
      params:
      - name: produce-numbers-Output-loop-item
        value: $(tasks.produce-numbers.results.output)
      - name: threshold
        value: $(params.threshold)
      taskSpec:
        apiVersion: custom.tekton.dev/v1alpha1
        kind: PipelineLoop
        spec:
          pipelineSpec:
            params:
            - name: produce-numbers-Output-loop-item
              type: string
            - name: threshold
              type: string
            tasks:
            - name: add-numbers
              params:
              - name: produce-numbers-Output-loop-item
                value: $(params.produce-numbers-Output-loop-item)
              taskSpec:
                steps:
                - name: main
                  args:
                  - --a
                  - $(inputs.params.produce-numbers-Output-loop-item)
                  - --b
                  - '10'
                  - '----output-paths'
                  - $(results.output.path)
                  command:
                  - sh
                  - -ec
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def add_numbers(a, b):
                        print(a + b)
                        return a + b

                    def _serialize_int(int_value: int) -> str:
                        if isinstance(int_value, str):
                            return int_value
                        if not isinstance(int_value, int):
                            raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
                        return str(int_value)

                    import argparse
                    _parser = argparse.ArgumentParser(prog='Add numbers', description='')
                    _parser.add_argument("--a", dest="a", type=int, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--b", dest="b", type=int, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
                    _parsed_args = vars(_parser.parse_args())
                    _output_files = _parsed_args.pop("_output_paths", [])

                    _outputs = add_numbers(**_parsed_args)

                    _outputs = [_outputs]

                    _output_serializers = [
                        _serialize_int,

                    ]

                    import os
                    for idx, output_file in enumerate(_output_files):
                        try:
                            os.makedirs(os.path.dirname(output_file))
                        except OSError:
                            pass
                        with open(output_file, 'w') as f:
                            f.write(_output_serializers[idx](_outputs[idx]))
                  image: python:3.7
                params:
                - name: produce-numbers-Output-loop-item
                  type: string
                results:
                - name: output
                  description: /tmp/outputs/Output/data
                metadata:
                  labels:
                    pipelines.kubeflow.org/pipelinename: ''
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/cache_enabled: "true"
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": ["--a", {"inputValue": "a"}, "--b", {"inputValue":
                      "b"}, "----output-paths", {"outputPath": "Output"}], "command":
                      ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
                      > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
                      "def add_numbers(a, b):\n    print(a + b)\n    return a + b\n\ndef
                      _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,
                      str):\n        return int_value\n    if not isinstance(int_value,
                      int):\n        raise TypeError(''Value \"{}\" has type \"{}\"
                      instead of int.''.format(str(int_value), str(type(int_value))))\n    return
                      str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Add
                      numbers'', description='''')\n_parser.add_argument(\"--a\",
                      dest=\"a\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--b\",
                      dest=\"b\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
                      dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
                      = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = add_numbers(**_parsed_args)\n\n_outputs
                      = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport
                      os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
                      OSError:\n        pass\n    with open(output_file, ''w'') as
                      f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
                      "image": "python:3.7"}}, "inputs": [{"name": "a", "type": "Integer"},
                      {"name": "b", "type": "Integer"}], "name": "Add numbers", "outputs":
                      [{"name": "Output", "type": "Integer"}]}'
                    tekton.dev/template: ''
              timeout: 525600m
            - name: print-number
              params:
              - name: add-numbers-Output
                value: $(tasks.add-numbers.results.output)
              taskSpec:
                steps:
                - name: main
                  args:
                  - --a
                  - $(inputs.params.add-numbers-Output)
                  - '----output-paths'
                  - $(results.output.path)
                  command:
                  - sh
                  - -ec
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def print_number(a):
                        print(a)
                        return a

                    def _serialize_int(int_value: int) -> str:
                        if isinstance(int_value, str):
                            return int_value
                        if not isinstance(int_value, int):
                            raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
                        return str(int_value)

                    import argparse
                    _parser = argparse.ArgumentParser(prog='Print number', description='')
                    _parser.add_argument("--a", dest="a", type=int, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
                    _parsed_args = vars(_parser.parse_args())
                    _output_files = _parsed_args.pop("_output_paths", [])

                    _outputs = print_number(**_parsed_args)

                    _outputs = [_outputs]

                    _output_serializers = [
                        _serialize_int,

                    ]

                    import os
                    for idx, output_file in enumerate(_output_files):
                        try:
                            os.makedirs(os.path.dirname(output_file))
                        except OSError:
                            pass
                        with open(output_file, 'w') as f:
                            f.write(_output_serializers[idx](_outputs[idx]))
                  image: python:3.7
                params:
                - name: add-numbers-Output
                  type: string
                results:
                - name: output
                  description: /tmp/outputs/Output/data
                metadata:
                  labels:
                    pipelines.kubeflow.org/pipelinename: ''
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/cache_enabled: "true"
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": ["--a", {"inputValue": "a"}, "----output-paths", {"outputPath":
                      "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
                      \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\"
                      \"$@\"\n", "def print_number(a):\n    print(a)\n    return a\n\ndef
                      _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,
                      str):\n        return int_value\n    if not isinstance(int_value,
                      int):\n        raise TypeError(''Value \"{}\" has type \"{}\"
                      instead of int.''.format(str(int_value), str(type(int_value))))\n    return
                      str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Print
                      number'', description='''')\n_parser.add_argument(\"--a\", dest=\"a\",
                      type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
                      dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
                      = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = print_number(**_parsed_args)\n\n_outputs
                      = [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport
                      os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
                      OSError:\n        pass\n    with open(output_file, ''w'') as
                      f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
                      "image": "python:3.7"}}, "inputs": [{"name": "a", "type": "Integer"}],
                      "name": "Print number", "outputs": [{"name": "Output", "type":
                      "Integer"}]}'
                    tekton.dev/template: ''
              timeout: 525600m
            - name: notify-success
              taskSpec:
                steps:
                - name: main
                  command:
                  - sh
                  - -ec
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def notify_success():
                        print('SUCCESS!')

                    import argparse
                    _parser = argparse.ArgumentParser(prog='Notify success', description='')
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = notify_success(**_parsed_args)
                  image: python:3.7
                metadata:
                  labels:
                    pipelines.kubeflow.org/pipelinename: ''
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/cache_enabled: "true"
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": [], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
                      \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\"
                      \"$@\"\n", "def notify_success():\n    print(''SUCCESS!'')\n\nimport
                      argparse\n_parser = argparse.ArgumentParser(prog=''Notify success'',
                      description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
                      = notify_success(**_parsed_args)\n"], "image": "python:3.7"}},
                      "name": "Notify success"}'
                    tekton.dev/template: ''
              when:
              - input: $(tasks.condition-2.results.outcome)
                operator: in
                values:
                - "true"
              timeout: 525600m
            - name: notify-failure
              taskSpec:
                steps:
                - name: main
                  command:
                  - sh
                  - -ec
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def notify_failure():
                        print('FAILED!')

                    import argparse
                    _parser = argparse.ArgumentParser(prog='Notify failure', description='')
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = notify_failure(**_parsed_args)
                  image: python:3.7
                metadata:
                  labels:
                    pipelines.kubeflow.org/pipelinename: ''
                    pipelines.kubeflow.org/generation: ''
                    pipelines.kubeflow.org/cache_enabled: "true"
                  annotations:
                    pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
                      {"args": [], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
                      \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\"
                      \"$@\"\n", "def notify_failure():\n    print(''FAILED!'')\n\nimport
                      argparse\n_parser = argparse.ArgumentParser(prog=''Notify failure'',
                      description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
                      = notify_failure(**_parsed_args)\n"], "image": "python:3.7"}},
                      "name": "Notify failure"}'
                    tekton.dev/template: ''
              when:
              - input: $(tasks.condition-3.results.outcome)
                operator: in
                values:
                - "true"
              timeout: 525600m
            - name: condition-2
              params:
              - name: operand1
                value: $(tasks.print-number.results.output)
              - name: operand2
                value: $(params.threshold)
              - name: operator
                value: '>'
              taskSpec:
                results:
                - name: outcome
                  description: Conditional task outcome
                params:
                - name: operand1
                  type: string
                - name: operand2
                  type: string
                - name: operator
                  type: string
                steps:
                - script: |-
                    python -c 'import sys
                    input1=str.rstrip(sys.argv[1])
                    input2=str.rstrip(sys.argv[2])
                    try:
                      input1=int(input1)
                      input2=int(input2)
                    except:
                      input1=str(input1)
                    outcome="true" if (input1 $(inputs.params.operator) input2) else "false"
                    f = open("/tekton/results/outcome", "w")
                    f.write(outcome)
                    f.close()' '$(inputs.params.operand1)' '$(inputs.params.operand2)'
                  image: python:alpine3.6
            - name: condition-3
              params:
              - name: operand1
                value: $(tasks.print-number.results.output)
              - name: operand2
                value: $(params.threshold)
              - name: operator
                value: <=
              taskSpec:
                results:
                - name: outcome
                  description: Conditional task outcome
                params:
                - name: operand1
                  type: string
                - name: operand2
                  type: string
                - name: operator
                  type: string
                steps:
                - script: |-
                    python -c 'import sys
                    input1=str.rstrip(sys.argv[1])
                    input2=str.rstrip(sys.argv[2])
                    try:
                      input1=int(input1)
                      input2=int(input2)
                    except:
                      input1=str(input1)
                    outcome="true" if (input1 $(inputs.params.operator) input2) else "false"
                    f = open("/tekton/results/outcome", "w")
                    f.write(outcome)
                    f.close()' '$(inputs.params.operand1)' '$(inputs.params.operand2)'
                  image: python:alpine3.6
          iterateParam: produce-numbers-Output-loop-item
  timeout: 525600m
