apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Pipeline that passes small
      pipeline parameter string to to consumer", "inputs": [{"name": "text", "type":
      "String"}], "name": "Pipeline parameter to consumer pipeline"}'
    sidecar.istio.io/inject: 'false'
    tekton.dev/input_artifacts: '{}'
    tekton.dev/output_artifacts: '{}'
  labels:
    pipelines.kubeflow.org/pipeline-sdk-type: kfp
  name: pipeline-parameter-to-consumer-pipeline
spec:
  params:
  - name: text
    value: ''
  pipelineSpec:
    params:
    - name: text
    tasks:
    - name: print-small-text
      params:
      - name: text
        value: $(params.text)
      taskSpec:
        params:
        - name: text
        steps:
        - args:
          - --text
          - $(inputs.params.text)
          command:
          - python3
          - -u
          - -c
          - "def print_small_text(text ):\n    '''Print small text'''\n    print(text)\n\
            \nimport argparse\n_parser = argparse.ArgumentParser(prog='Print small\
            \ text', description='Print small text')\n_parser.add_argument(\"--text\"\
            , dest=\"text\", type=str, required=True, default=argparse.SUPPRESS)\n\
            _parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
            _output_paths\", [])\n\n_outputs = print_small_text(**_parsed_args)\n\n\
            _output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
