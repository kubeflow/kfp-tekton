apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"name": "Text splitting pipeline2"}'
    sidecar.istio.io/inject: 'false'
    tekton.dev/input_artifacts: '{}'
    tekton.dev/output_artifacts: '{}'
  labels:
    pipelines.kubeflow.org/pipeline-sdk-type: kfp
  name: text-splitting-pipeline2
spec:
  pipelineSpec:
    tasks:
    - name: split-text-lines2
      taskSpec:
        stepTemplate:
          volumeMounts:
          - mountPath: /tmp/inputs/source
            name: source
        steps:
        - image: busybox
          name: copy-inputs
          script: '#!/bin/sh

            set -exo pipefail

            echo -n "one

            two

            three

            four

            five

            six

            seven

            eight

            nine

            ten" > /tmp/inputs/source/data

            '
        - args:
          - --source
          - /tmp/inputs/source/data
          - --odd-lines
          - $(workspaces.split-text-lines2.path)/split-text-lines2-odd_lines
          - --even-lines
          - $(workspaces.split-text-lines2.path)/split-text-lines2-even_lines
          command:
          - python3
          - -u
          - -c
          - "def _parent_dirs_maker_that_returns_open_file(mode: str, encoding: str\
            \ = None):\n    def make_parent_dirs_and_return_path(file_path: str):\n\
            \        import os\n        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n\
            \        return open(file_path, mode=mode, encoding=encoding)\n    return\
            \ make_parent_dirs_and_return_path\n\ndef split_text_lines2(source_file\
            \ , odd_lines_file , even_lines_file ):\n    while True:\n        line\
            \ = source_file.readline()\n        if line == \"\":\n            break\n\
            \        odd_lines_file.write(line)\n        line = source_file.readline()\n\
            \        if line == \"\":\n            break\n        even_lines_file.write(line)\n\
            \nimport argparse\n_parser = argparse.ArgumentParser(prog='Split text\
            \ lines2', description='')\n_parser.add_argument(\"--source\", dest=\"\
            source_file\", type=argparse.FileType('rt'), required=True, default=argparse.SUPPRESS)\n\
            _parser.add_argument(\"--odd-lines\", dest=\"odd_lines_file\", type=_parent_dirs_maker_that_returns_open_file('wt'),\
            \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--even-lines\"\
            , dest=\"even_lines_file\", type=_parent_dirs_maker_that_returns_open_file('wt'),\
            \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
            _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs =\
            \ split_text_lines2(**_parsed_args)\n\n_output_serializers = [\n\n]\n\n\
            import os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
            \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
            \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
        volumes:
        - emptyDir: {}
          name: source
        workspaces:
        - name: split-text-lines2
      workspaces:
      - name: split-text-lines2
        workspace: text-splitting-pipeline2
    - name: print-text
      runAfter:
      - split-text-lines2
      taskSpec:
        steps:
        - args:
          - --text
          - $(workspaces.print-text.path)/split-text-lines2-odd_lines
          command:
          - python3
          - -u
          - -c
          - "def print_text(text_path ): # The \"text\" input is untyped so that any\
            \ data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end = '')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
        workspaces:
        - name: print-text
      workspaces:
      - name: print-text
        workspace: text-splitting-pipeline2
    - name: print-text-2
      runAfter:
      - split-text-lines2
      taskSpec:
        steps:
        - args:
          - --text
          - $(workspaces.print-text-2.path)/split-text-lines2-even_lines
          command:
          - python3
          - -u
          - -c
          - "def print_text(text_path ): # The \"text\" input is untyped so that any\
            \ data can be printed\n    '''Print text'''\n    with open(text_path,\
            \ 'r') as reader:\n        for line in reader:\n            print(line,\
            \ end = '')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Print\
            \ text', description='Print text')\n_parser.add_argument(\"--text\", dest=\"\
            text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args\
            \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
            , [])\n\n_outputs = print_text(**_parsed_args)\n\n_output_serializers\
            \ = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
            \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except\
            \ OSError:\n        pass\n    with open(output_file, 'w') as f:\n    \
            \    f.write(_output_serializers[idx](_outputs[idx]))\n"
          image: tensorflow/tensorflow:1.13.2-py3
          name: main
        workspaces:
        - name: print-text-2
      workspaces:
      - name: print-text-2
        workspace: text-splitting-pipeline2
    workspaces:
    - name: text-splitting-pipeline2
  workspaces:
  - name: text-splitting-pipeline2
    persistentVolumeClaim:
      claimName: text-splitting-pipeline2
