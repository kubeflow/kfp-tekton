{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data passing tutorial\n",
    "Data passing is the most important aspect of Pipelines.\n",
    "\n",
    "In Kubeflow Pipelines, the pipeline authors compose pipelines by creating component instances (tasks) and connecting them together.\n",
    "\n",
    "Component have inputs and outputs. They can consume and produce arbitrary data.\n",
    "\n",
    "Pipeline authors establish connections between component tasks by connecting their data inputs and outputs - by passing the output of one task as an argument to another task's input.\n",
    "\n",
    "The system takes care of storing the data produced by components and later passing that data to other components for consumption as instructed by the pipeline.\n",
    "\n",
    "This tutorial shows how to create python components that produce, consume and transform data.\n",
    "It shows how to create data passing pipelines by instantiating components and connecting them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp.components import InputPath, InputTextFile, OutputPath, OutputTextFile\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp_tekton.compiler import TektonCompiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small data\n",
    "\n",
    "Small data is the data that you'll be comfortable passing as program's command-line argument. Small data size should not exceed few kilobytes.\n",
    "\n",
    "Some examples of typical types of small data are: number, URL, small string (e.g. column name).\n",
    "\n",
    "Small lists, dictionaries and JSON structures are fine, but keep an eye on the size and consider switching to file-based data passing methods that are more suitable for big data (more than several kilobytes) or binary data.\n",
    "\n",
    "All small data outputs will be at some point serialized to strings and all small data input values will be at some point deserialized from strings (passed as command-line argumants). There are built-in serializers and deserializers for several common types (e.g. `str`, `int`, `float`, `bool`, `list`, `dict`). All other types of data need to be serialized manually before returning the data. Make sure to properly specify type annotations, otherwize there would be no automatic deserialization and the component function will receive strings instead of deserialized objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consuming small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def print_small_text(text: str):\n",
    "    '''Print small text'''\n",
    "    print(text)\n",
    "\n",
    "def constant_to_consumer_pipeline():\n",
    "    '''Pipeline that passes small constant string to to consumer'''\n",
    "    consume_task = print_small_text('Hello world') # Passing constant as argument to consumer\n",
    "\n",
    "TektonCompiler().compile(constant_to_consumer_pipeline,\n",
    "                         'constant_to_consumer_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/print-small-text created\n",
      "pipeline.tekton.dev/constant-to-consumer-pipeline created\n",
      "pipelinerun.tekton.dev/constant-to-consumer-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f constant_to_consumer_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           constant-to-consumer-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   constant-to-consumer-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED                DURATION    STATUS\r\n",
      "373 milliseconds ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " No params\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                         TASK NAME          STARTED                DURATION    STATUS\r\n",
      " ∙ constant-to-consumer-pipeline-run-print-small-text-wj9p4   print-small-text   373 milliseconds ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe constant-to-consumer-pipeline-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_parameter_to_consumer_pipeline(text: str):\n",
    "    '''Pipeline that passes small pipeline parameter string to to consumer'''\n",
    "    consume_task = print_small_text(text) # Passing pipeline parameter as argument to consumer\n",
    "\n",
    "TektonCompiler().compile(pipeline_parameter_to_consumer_pipeline,\n",
    "                         'pipeline_parameter_to_consumer_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/print-small-text configured\n",
      "pipeline.tekton.dev/pipeline-parameter-to-consumer-pipeline created\n",
      "pipelinerun.tekton.dev/pipeline-parameter-to-consumer-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f pipeline_parameter_to_consumer_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           pipeline-parameter-to-consumer-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   pipeline-parameter-to-consumer-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED                 DURATION    STATUS\r\n",
      "206 milliseconds ago   5 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " NAME     VALUE\r\n",
      " ∙ text   \r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                                TASK NAME          STARTED                 DURATION    STATUS\r\n",
      " ∙ pipeline-parameter-to-consumer-pipeline-run-print-small-t-mr7fl   print-small-text   206 milliseconds ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe pipeline-parameter-to-consumer-pipeline-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def produce_one_small_output() -> str:\n",
    "    return 'Hello world'\n",
    "\n",
    "def task_output_to_consumer_pipeline():\n",
    "    '''Pipeline that passes small data from producer to consumer'''\n",
    "    produce_task = produce_one_small_output()\n",
    "    # Passing producer task output as argument to consumer\n",
    "    consume_task1 = print_small_text(produce_task.output) # task.output only works for single-output components\n",
    "    consume_task2 = print_small_text(produce_task.outputs['output']) # task.outputs[...] always works\n",
    "\n",
    "TektonCompiler().compile(task_output_to_consumer_pipeline,\n",
    "                         'task_output_to_consumer_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/produce-one-small-output created\n",
      "task.tekton.dev/print-small-text configured\n",
      "task.tekton.dev/print-small-text-2 created\n",
      "pipeline.tekton.dev/task-output-to-consumer-pipeline created\n",
      "pipelinerun.tekton.dev/task-output-to-consumer-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f task_output_to_consumer_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           task-output-to-consumer-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   task-output-to-consumer-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED         DURATION    STATUS\r\n",
      "4 minutes ago   8 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " No params\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                                TASK NAME                  STARTED         DURATION    STATUS\r\n",
      " ∙ task-output-to-consumer-pipeline-run-print-small-text-2-rpcmf     print-small-text-2         4 minutes ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ task-output-to-consumer-pipeline-run-print-small-text-gqsnc       print-small-text           4 minutes ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ task-output-to-consumer-pipeline-run-produce-one-small-ou-l48pb   produce-one-small-output   4 minutes ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe task-output-to-consumer-pipeline-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing and consuming multiple arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def produce_two_small_outputs() -> NamedTuple('Outputs', [('text', str), ('number', int)]):\n",
    "    return (\"data 1\", 42)\n",
    "\n",
    "@func_to_container_op\n",
    "def consume_two_arguments(text: str, number: int):\n",
    "    print('Text={}'.format(text))\n",
    "    print('Number={}'.format(str(number)))\n",
    "\n",
    "def producers_to_consumers_pipeline(text: str = \"Hello world\"):\n",
    "    '''Pipeline that passes data from producer to consumer'''\n",
    "    produce1_task = produce_one_small_output()\n",
    "    produce2_task = produce_two_small_outputs()\n",
    "\n",
    "    consume_task1 = consume_two_arguments(produce1_task.output, 42)\n",
    "    consume_task2 = consume_two_arguments(text, produce2_task.outputs['number'])\n",
    "    consume_task3 = consume_two_arguments(produce2_task.outputs['text'], produce2_task.outputs['number'])\n",
    "\n",
    "TektonCompiler().compile(producers_to_consumers_pipeline,\n",
    "                         'producers_to_consumers_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/produce-one-small-output configured\n",
      "task.tekton.dev/produce-two-small-outputs created\n",
      "task.tekton.dev/consume-two-arguments created\n",
      "task.tekton.dev/consume-two-arguments-2 created\n",
      "task.tekton.dev/consume-two-arguments-3 created\n",
      "pipeline.tekton.dev/producers-to-consumers-pipeline created\n",
      "pipelinerun.tekton.dev/producers-to-consumers-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f producers_to_consumers_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           producers-to-consumers-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   producers-to-consumers-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED         DURATION     STATUS\r\n",
      "4 minutes ago   12 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " NAME     VALUE\r\n",
      " ∙ text   Hello world\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                                TASK NAME                   STARTED         DURATION    STATUS\r\n",
      " ∙ producers-to-consumers-pipeline-run-consume-two-arguments-ncb5m   consume-two-arguments-2     4 minutes ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ producers-to-consumers-pipeline-run-consume-two-arguments-nh8b9   consume-two-arguments-3     4 minutes ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ producers-to-consumers-pipeline-run-consume-two-arguments-v855p   consume-two-arguments       4 minutes ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ producers-to-consumers-pipeline-run-produce-one-small-out-r5fkh   produce-one-small-output    4 minutes ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ producers-to-consumers-pipeline-run-produce-two-small-out-h8jh2   produce-two-small-outputs   4 minutes ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe producers-to-consumers-pipeline-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consuming and producing data at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def get_item_from_list(list_of_strings: list, index: int) -> str:\n",
    "    return list_of_strings[index]\n",
    "\n",
    "@func_to_container_op\n",
    "def truncate_text(text: str, max_length: int) -> str:\n",
    "    return text[0:max_length]\n",
    "\n",
    "def processing_pipeline(text: str = \"Hello world\"):\n",
    "    truncate_task = truncate_text(text, max_length=5)\n",
    "    get_item_task = get_item_from_list(list_of_strings=[3, 1, truncate_task.output, 1, 5, 9, 2, 6, 7], index=2)\n",
    "    print_small_text(get_item_task.output)\n",
    "\n",
    "\n",
    "TektonCompiler().compile(processing_pipeline,\n",
    "                         'processing_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/truncate-text created\n",
      "task.tekton.dev/get-item-from-list created\n",
      "task.tekton.dev/print-small-text configured\n",
      "pipeline.tekton.dev/processing-pipeline created\n",
      "pipelinerun.tekton.dev/processing-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f processing_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           processing-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   processing-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED         DURATION     STATUS\r\n",
      "5 minutes ago   13 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " NAME     VALUE\r\n",
      " ∙ text   Hello world\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                 TASK NAME            STARTED         DURATION    STATUS\r\n",
      " ∙ processing-pipeline-run-print-small-text-7g484     print-small-text     5 minutes ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ processing-pipeline-run-get-item-from-list-fcfq8   get-item-from-list   5 minutes ago   4 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ processing-pipeline-run-truncate-text-cnr7x        truncate-text        5 minutes ago   5 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe processing-pipeline-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## big data (files)\n",
    "\n",
    "big data should be read from files and written to files.\n",
    "\n",
    "The paths for the input and output files are chosen by the system and are passed into the function (as strings).\n",
    "\n",
    "Use the `InputPath` parameter annotation to tell the system that the function wants to consume the corresponding input data as a file. The system will download the data, write it to a local file and then pass the **path** of that file to the function.\n",
    "\n",
    "Use the `OutputPath` parameter annotation to tell the system that the function wants to produce the corresponding output data as a file. The system will prepare and pass the **path** of a file where the function should write the output data. After the function exits, the system will upload the data to the storage system so that it can be passed to downstream components.\n",
    "\n",
    "You can specify the type of the consumed/produced data by specifying the type argument to `InputPath` and `OutputPath`. The type can be a python type or an arbitrary type name string. `OutputPath('TFModel')` means that the function states that the data it has written to a file has type 'TFModel'. `InputPath('TFModel')` means that the function states that it expect the data it reads from a file to have type 'TFModel'. When the pipeline author connects inputs to outputs the system checks whether the types match.\n",
    "\n",
    "Note on input/output names: When the function is converted to component, the input and output names generally follow the parameter names, but the \"\\_path\" and \"\\_file\" suffixes are stripped from file/path inputs and outputs. E.g. the `number_file_path: InputPath(int)` parameter becomes the `number: int` input. This makes the argument passing look more natural: `number=42` instead of `number_file_path=42`.\n",
    "\n",
    "Notes: As we used 'workspaces' in Tekton pipelines to handle big data processing, the compiler will generate the PVC definitions and needs the volume to store the data.\n",
    "User need to create volume manually, or enable dynamic volume provisioning, refer to the link of:\n",
    "https://kubernetes.io/docs/concepts/storage/dynamic-provisioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Writing and reading big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing big data\n",
    "@func_to_container_op\n",
    "def repeat_line(line: str, output_text_path: OutputPath(str), count: int = 10):\n",
    "    '''Repeat the line specified number of times'''\n",
    "    with open(output_text_path, 'w') as writer:\n",
    "        for i in range(count):\n",
    "            writer.write(line + '\\n')\n",
    "\n",
    "\n",
    "# Reading big data\n",
    "@func_to_container_op\n",
    "def print_text(text_path: InputPath()): # The \"text\" input is untyped so that any data can be printed\n",
    "    '''Print text'''\n",
    "    with open(text_path, 'r') as reader:\n",
    "        for line in reader:\n",
    "            print(line, end = '')\n",
    "\n",
    "def print_repeating_lines_pipeline():\n",
    "    repeat_lines_task = repeat_line(line='Hello', count=5000)\n",
    "    print_text(repeat_lines_task.output) # Don't forget .output !\n",
    "\n",
    "TektonCompiler().compile(print_repeating_lines_pipeline,\n",
    "                         'print_repeating_lines_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/repeat-line created\n",
      "task.tekton.dev/print-text created\n",
      "pipeline.tekton.dev/print-repeating-lines-pipeline created\n",
      "pipelinerun.tekton.dev/print-repeating-lines-pipeline-run created\n",
      "persistentvolumeclaim/print-repeating-lines-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f print_repeating_lines_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           print-repeating-lines-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   print-repeating-lines-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED          DURATION     STATUS\r\n",
      "12 seconds ago   11 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " No params\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                     TASK NAME     STARTED          DURATION    STATUS\r\n",
      " ∙ print-repeating-lines-pipeline-run-print-text-xdzcj    print-text    6 seconds ago    5 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ print-repeating-lines-pipeline-run-repeat-line-lcvrf   repeat-line   12 seconds ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe print-repeating-lines-pipeline-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def split_text_lines(source_path: InputPath(str), odd_lines_path: OutputPath(str), even_lines_path: OutputPath(str)):\n",
    "    with open(source_path, 'r') as reader:\n",
    "        with open(odd_lines_path, 'w') as odd_writer:\n",
    "            with open(even_lines_path, 'w') as even_writer:\n",
    "                while True:\n",
    "                    line = reader.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    odd_writer.write(line)\n",
    "                    line = reader.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    even_writer.write(line)\n",
    "\n",
    "def text_splitting_pipeline():\n",
    "    text = '\\n'.join(['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])\n",
    "    split_text_task = split_text_lines(text)\n",
    "    print_text(split_text_task.outputs['odd_lines'])\n",
    "    print_text(split_text_task.outputs['even_lines'])\n",
    "\n",
    "TektonCompiler().compile(text_splitting_pipeline,\n",
    "                         'text_splitting_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/split-text-lines created\n",
      "task.tekton.dev/print-text configured\n",
      "task.tekton.dev/print-text-2 created\n",
      "pipeline.tekton.dev/text-splitting-pipeline created\n",
      "pipelinerun.tekton.dev/text-splitting-pipeline-run created\n",
      "persistentvolumeclaim/text-splitting-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f text_splitting_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           text-splitting-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   text-splitting-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED        DURATION   STATUS\r\n",
      "1 minute ago   1 minute   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " No params\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                   TASK NAME          STARTED          DURATION    STATUS\r\n",
      " ∙ text-splitting-pipeline-run-print-text-2-25xs2       print-text-2       16 seconds ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ text-splitting-pipeline-run-print-text-kbq4v         print-text         16 seconds ago   6 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ text-splitting-pipeline-run-split-text-lines-dmtqx   split-text-lines   1 minute ago     1 minute    \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe text-splitting-pipeline-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing big data with pre-opened files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def split_text_lines2(source_file: InputTextFile(str), odd_lines_file: OutputTextFile(str), even_lines_file: OutputTextFile(str)):\n",
    "    while True:\n",
    "        line = source_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        odd_lines_file.write(line)\n",
    "        line = source_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        even_lines_file.write(line)\n",
    "\n",
    "def text_splitting_pipeline2():\n",
    "    text = '\\n'.join(['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])\n",
    "    split_text_task = split_text_lines2(text)\n",
    "    print_text(split_text_task.outputs['odd_lines']).set_display_name('Odd lines')\n",
    "    print_text(split_text_task.outputs['even_lines']).set_display_name('Even lines')\n",
    "\n",
    "TektonCompiler().compile(text_splitting_pipeline2,\n",
    "                         'text_splitting_pipeline2.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/split-text-lines2 created\n",
      "task.tekton.dev/print-text configured\n",
      "task.tekton.dev/print-text-2 configured\n",
      "pipeline.tekton.dev/text-splitting-pipeline2 created\n",
      "pipelinerun.tekton.dev/text-splitting-pipeline2-run created\n",
      "persistentvolumeclaim/text-splitting-pipeline2-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f text_splitting_pipeline2.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           text-splitting-pipeline2-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   text-splitting-pipeline2\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED          DURATION     STATUS\r\n",
      "48 seconds ago   48 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " No params\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                                     TASK NAME           STARTED          DURATION     STATUS\r\n",
      " ∙ text-splitting-pipeline2-run-print-text-2-5gfrz        print-text-2        6 seconds ago    6 seconds    \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ text-splitting-pipeline2-run-print-text-ckdcr          print-text          6 seconds ago    6 seconds    \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ text-splitting-pipeline2-run-split-text-lines2-xwlvh   split-text-lines2   48 seconds ago   42 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe text-splitting-pipeline2-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Pipeline that generates then sums many numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing many numbers\n",
    "@func_to_container_op\n",
    "def write_numbers(numbers_path: OutputPath(str), start: int = 0, count: int = 10):\n",
    "    with open(numbers_path, 'w') as writer:\n",
    "        for i in range(start, count):\n",
    "            writer.write(str(i) + '\\n')\n",
    "\n",
    "\n",
    "# Reading and summing many numbers\n",
    "@func_to_container_op\n",
    "def sum_numbers(numbers_path: InputPath(str)) -> int:\n",
    "    sum = 0\n",
    "    with open(numbers_path, 'r') as reader:\n",
    "        for line in reader:\n",
    "            sum = sum + int(line)\n",
    "    return sum\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline to sum 100000 numbers\n",
    "def sum_pipeline(count: 'Integer' = 100000):\n",
    "    numbers_task = write_numbers(count=count)\n",
    "    print_text(numbers_task.output)\n",
    "\n",
    "    sum_task = sum_numbers(numbers_task.outputs['numbers'])\n",
    "    print_text(sum_task.output)\n",
    "\n",
    "TektonCompiler().compile(sum_pipeline,\n",
    "                         'sum_pipeline.yaml',\n",
    "                         generate_pipelinerun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task.tekton.dev/write-numbers created\n",
      "task.tekton.dev/print-text configured\n",
      "task.tekton.dev/sum-numbers created\n",
      "task.tekton.dev/print-text-2 configured\n",
      "pipeline.tekton.dev/sum-pipeline created\n",
      "pipelinerun.tekton.dev/sum-pipeline-run created\n",
      "persistentvolumeclaim/sum-pipeline-run created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f sum_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m:           sum-pipeline-run\r\n",
      "\u001b[1mNamespace\u001b[0m:      kubeflow\r\n",
      "\u001b[1mPipeline Ref\u001b[0m:   sum-pipeline\r\n",
      "\r\n",
      "🌡️  \u001b[4;1mStatus\r\n",
      "\u001b[0m\r\n",
      "STARTED          DURATION     STATUS\r\n",
      "45 seconds ago   40 seconds   \u001b[92mSucceeded\u001b[0m\r\n",
      "\r\n",
      "📦 \u001b[4;1mResources\r\n",
      "\u001b[0m\r\n",
      " No resources\r\n",
      "\r\n",
      "⚓ \u001b[4;1mParams\r\n",
      "\u001b[0m\r\n",
      " NAME      VALUE\r\n",
      " ∙ count   100000\r\n",
      "\r\n",
      "🗂  \u001b[4;1mTaskruns\r\n",
      "\u001b[0m\r\n",
      " NAME                                     TASK NAME       STARTED          DURATION     STATUS\r\n",
      " ∙ sum-pipeline-run-print-text-2-k68zl    print-text-2    10 seconds ago   5 seconds    \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ sum-pipeline-run-sum-numbers-9k4s7     sum-numbers     15 seconds ago   5 seconds    \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ sum-pipeline-run-print-text-r6blr      print-text      16 seconds ago   6 seconds    \u001b[92mSucceeded\u001b[0m\r\n",
      " ∙ sum-pipeline-run-write-numbers-9mdfq   write-numbers   45 seconds ago   29 seconds   \u001b[92mSucceeded\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tkn pr describe sum-pipeline-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
