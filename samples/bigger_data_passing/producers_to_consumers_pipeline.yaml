apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"name": "Produce one small output", "outputs":
      [{"name": "Output", "type": "String"}]}'
  name: produce-one-small-output
spec:
  results:
  - description: /tmp/outputs/Output/data
    name: output
  steps:
  - args:
    - '----output-paths'
    - $(results.output.path)
    command:
    - python3
    - -u
    - -c
    - "def produce_one_small_output()  :\n    return 'Hello world'\n\ndef _serialize_str(str_value:\
      \ str) -> str:\n    if not isinstance(str_value, str):\n        raise TypeError('Value\
      \ \"{}\" has type \"{}\" instead of str.'.format(str(str_value), str(type(str_value))))\n\
      \    return str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Produce\
      \ one small output', description='')\n_parser.add_argument(\"----output-paths\"\
      , dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_one_small_output(**_parsed_args)\n\
      \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n\
      ]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
      \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n  \
      \      pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"name": "Produce two small outputs",
      "outputs": [{"name": "text", "type": "String"}, {"name": "number", "type": "Integer"}]}'
  name: produce-two-small-outputs
spec:
  results:
  - description: /tmp/outputs/text/data
    name: text
  - description: /tmp/outputs/number/data
    name: number
  steps:
  - args:
    - '----output-paths'
    - $(results.text.path)
    - $(results.number.path)
    command:
    - python3
    - -u
    - -c
    - "def produce_two_small_outputs()      :\n    return (\"data 1\", 42)\n\ndef\
      \ _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value, str):\n\
      \        raise TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(str(str_value),\
      \ str(type(str_value))))\n    return str_value\n\ndef _serialize_int(int_value:\
      \ int) -> str:\n    if isinstance(int_value, str):\n        return int_value\n\
      \    if not isinstance(int_value, int):\n        raise TypeError('Value \"{}\"\
      \ has type \"{}\" instead of int.'.format(str(int_value), str(type(int_value))))\n\
      \    return str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Produce\
      \ two small outputs', description='')\n_parser.add_argument(\"----output-paths\"\
      , dest=\"_output_paths\", type=str, nargs=2)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = produce_two_small_outputs(**_parsed_args)\n\
      \n_output_serializers = [\n    _serialize_str,\n    _serialize_int,\n\n]\n\n\
      import os\nfor idx, output_file in enumerate(_output_files):\n    try:\n   \
      \     os.makedirs(os.path.dirname(output_file))\n    except OSError:\n     \
      \   pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"inputs": [{"name": "text", "type": "String"},
      {"name": "number", "type": "Integer"}], "name": "Consume two arguments"}'
  name: consume-two-arguments
spec:
  params:
  - name: produce-one-small-output-output
  steps:
  - args:
    - --text
    - $(inputs.params.produce-one-small-output-output)
    - --number
    - '42'
    command:
    - python3
    - -u
    - -c
    - "def consume_two_arguments(text , number ):\n    print('Text={}'.format(text))\n\
      \    print('Number={}'.format(str(number)))\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Consume\
      \ two arguments', description='')\n_parser.add_argument(\"--text\", dest=\"\
      text\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --number\", dest=\"number\", type=int, required=True, default=argparse.SUPPRESS)\n\
      _parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = consume_two_arguments(**_parsed_args)\n\n\
      _output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"inputs": [{"name": "text", "type": "String"},
      {"name": "number", "type": "Integer"}], "name": "Consume two arguments"}'
  name: consume-two-arguments-2
spec:
  params:
  - name: produce-two-small-outputs-number
  - name: text
  steps:
  - args:
    - --text
    - $(inputs.params.text)
    - --number
    - $(inputs.params.produce-two-small-outputs-number)
    command:
    - python3
    - -u
    - -c
    - "def consume_two_arguments(text , number ):\n    print('Text={}'.format(text))\n\
      \    print('Number={}'.format(str(number)))\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Consume\
      \ two arguments', description='')\n_parser.add_argument(\"--text\", dest=\"\
      text\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --number\", dest=\"number\", type=int, required=True, default=argparse.SUPPRESS)\n\
      _parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = consume_two_arguments(**_parsed_args)\n\n\
      _output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"inputs": [{"name": "text", "type": "String"},
      {"name": "number", "type": "Integer"}], "name": "Consume two arguments"}'
  name: consume-two-arguments-3
spec:
  params:
  - name: produce-two-small-outputs-number
  - name: produce-two-small-outputs-text
  steps:
  - args:
    - --text
    - $(inputs.params.produce-two-small-outputs-text)
    - --number
    - $(inputs.params.produce-two-small-outputs-number)
    command:
    - python3
    - -u
    - -c
    - "def consume_two_arguments(text , number ):\n    print('Text={}'.format(text))\n\
      \    print('Number={}'.format(str(number)))\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Consume\
      \ two arguments', description='')\n_parser.add_argument(\"--text\", dest=\"\
      text\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --number\", dest=\"number\", type=int, required=True, default=argparse.SUPPRESS)\n\
      _parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = consume_two_arguments(**_parsed_args)\n\n\
      _output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
---
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Pipeline that passes data
      from producer to consumer", "inputs": [{"default": "Hello world", "name": "text",
      "optional": true, "type": "String"}], "name": "Producers to consumers pipeline"}'
    sidecar.istio.io/inject: 'false'
  name: producers-to-consumers-pipeline
spec:
  params:
  - default: Hello world
    name: text
  tasks:
  - name: produce-one-small-output
    taskRef:
      name: produce-one-small-output
  - name: produce-two-small-outputs
    taskRef:
      name: produce-two-small-outputs
  - name: consume-two-arguments
    params:
    - name: produce-one-small-output-output
      value: $(tasks.produce-one-small-output.results.output)
    taskRef:
      name: consume-two-arguments
  - name: consume-two-arguments-2
    params:
    - name: produce-two-small-outputs-number
      value: $(tasks.produce-two-small-outputs.results.number)
    - name: text
      value: $(params.text)
    taskRef:
      name: consume-two-arguments-2
  - name: consume-two-arguments-3
    params:
    - name: produce-two-small-outputs-number
      value: $(tasks.produce-two-small-outputs.results.number)
    - name: produce-two-small-outputs-text
      value: $(tasks.produce-two-small-outputs.results.text)
    taskRef:
      name: consume-two-arguments-3
---
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: producers-to-consumers-pipeline-run
spec:
  params:
  - name: text
    value: Hello world
  pipelineRef:
    name: producers-to-consumers-pipeline
