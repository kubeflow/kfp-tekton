apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"inputs": [{"default": "0", "name": "start",
      "optional": true, "type": "Integer"}, {"default": "10", "name": "count", "optional":
      true, "type": "Integer"}], "name": "Write numbers", "outputs": [{"name": "numbers",
      "type": "String"}]}'
  name: write-numbers
spec:
  params:
  - name: count
  steps:
  - args:
    - --count
    - $(inputs.params.count)
    - --numbers
    - $(workspaces.write-numbers.path)/write-numbers-numbers
    command:
    - python3
    - -u
    - -c
    - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n   \
      \ os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
      \ndef write_numbers(numbers_path , start  = 0, count  = 10):\n    with open(numbers_path,\
      \ 'w') as writer:\n        for i in range(start, count):\n            writer.write(str(i)\
      \ + '\\n')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Write\
      \ numbers', description='')\n_parser.add_argument(\"--start\", dest=\"start\"\
      , type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --count\", dest=\"count\", type=int, required=False, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--numbers\", dest=\"numbers_path\", type=_make_parent_dirs_and_return_path,\
      \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = write_numbers(**_parsed_args)\n\
      \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
  workspaces:
  - name: write-numbers
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"description": "Print text", "inputs":
      [{"name": "text"}], "name": "Print text"}'
  name: print-text
spec:
  steps:
  - args:
    - --text
    - $(workspaces.print-text.path)/write-numbers-numbers
    command:
    - python3
    - -u
    - -c
    - "def print_text(text_path ): # The \"text\" input is untyped so that any data\
      \ can be printed\n    '''Print text'''\n    with open(text_path, 'r') as reader:\n\
      \        for line in reader:\n            print(line, end = '')\n\nimport argparse\n\
      _parser = argparse.ArgumentParser(prog='Print text', description='Print text')\n\
      _parser.add_argument(\"--text\", dest=\"text_path\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n_output_files\
      \ = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = print_text(**_parsed_args)\n\
      \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
  workspaces:
  - name: print-text
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"inputs": [{"name": "numbers", "type":
      "String"}], "name": "Sum numbers", "outputs": [{"name": "Output", "type": "Integer"}]}'
  name: sum-numbers
spec:
  steps:
  - args:
    - --numbers
    - $(workspaces.sum-numbers.path)/write-numbers-numbers
    - '----output-paths'
    - $(workspaces.sum-numbers.path)/sum-numbers-output
    command:
    - python3
    - -u
    - -c
    - "def sum_numbers(numbers_path )  :\n    sum = 0\n    with open(numbers_path,\
      \ 'r') as reader:\n        for line in reader:\n            sum = sum + int(line)\n\
      \    return sum\n\ndef _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,\
      \ str):\n        return int_value\n    if not isinstance(int_value, int):\n\
      \        raise TypeError('Value \"{}\" has type \"{}\" instead of int.'.format(str(int_value),\
      \ str(type(int_value))))\n    return str(int_value)\n\nimport argparse\n_parser\
      \ = argparse.ArgumentParser(prog='Sum numbers', description='')\n_parser.add_argument(\"\
      --numbers\", dest=\"numbers_path\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
      \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = sum_numbers(**_parsed_args)\n\n_outputs =\
      \ [_outputs]\n\n_output_serializers = [\n    _serialize_int,\n\n]\n\nimport\
      \ os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
      \    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n\
      \        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
  workspaces:
  - name: sum-numbers
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  annotations:
    pipelines.kubeflow.org/component_spec: '{"description": "Print text", "inputs":
      [{"name": "text"}], "name": "Print text"}'
  name: print-text-2
spec:
  steps:
  - args:
    - --text
    - $(workspaces.print-text-2.path)/sum-numbers-output
    command:
    - python3
    - -u
    - -c
    - "def print_text(text_path ): # The \"text\" input is untyped so that any data\
      \ can be printed\n    '''Print text'''\n    with open(text_path, 'r') as reader:\n\
      \        for line in reader:\n            print(line, end = '')\n\nimport argparse\n\
      _parser = argparse.ArgumentParser(prog='Print text', description='Print text')\n\
      _parser.add_argument(\"--text\", dest=\"text_path\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n_output_files\
      \ = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = print_text(**_parsed_args)\n\
      \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    image: tensorflow/tensorflow:1.13.2-py3
    name: main
  workspaces:
  - name: print-text-2
---
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  annotations:
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "100000", "name":
      "count", "optional": true, "type": "Integer"}], "name": "Sum pipeline"}'
    sidecar.istio.io/inject: 'false'
  name: sum-pipeline
spec:
  params:
  - default: '100000'
    name: count
  tasks:
  - name: write-numbers
    params:
    - name: count
      value: $(params.count)
    taskRef:
      name: write-numbers
    workspaces:
    - name: write-numbers
      workspace: sum-pipeline
  - name: print-text
    runAfter:
    - write-numbers
    taskRef:
      name: print-text
    workspaces:
    - name: print-text
      workspace: sum-pipeline
  - name: sum-numbers
    runAfter:
    - write-numbers
    taskRef:
      name: sum-numbers
    workspaces:
    - name: sum-numbers
      workspace: sum-pipeline
  - name: print-text-2
    runAfter:
    - sum-numbers
    taskRef:
      name: print-text-2
    workspaces:
    - name: print-text-2
      workspace: sum-pipeline
  workspaces:
  - name: sum-pipeline
---
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: sum-pipeline-run
spec:
  params:
  - name: count
    value: '100000'
  pipelineRef:
    name: sum-pipeline
  workspaces:
  - name: sum-pipeline
    persistentVolumeClaim:
      claimName: sum-pipeline-run
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sum-pipeline-run
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi
  volumeMode: Filesystem
